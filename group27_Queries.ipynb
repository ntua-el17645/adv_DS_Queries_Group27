{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca252275-a9cd-478d-bcbe-bea35af45861",
   "metadata": {},
   "source": [
    "# Query 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a63256f-3d2a-4135-bfe1-2b4a70d55ee8",
   "metadata": {},
   "source": [
    "#### Dataframe 4 executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4522497-7146-4f2c-9473-d087eee06816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>4192</td><td>application_1732639283265_4132</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_4132/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-178.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_4132_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Δημιουργία SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query1 Dataframe\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Φόρτωση δεδομένων από το S3 bucket και ύστερα ένωση με union δομή ώστε να έχουμε ολα τα data σε ένα Dataframe\n",
    "crime_data_2010 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "crime_data_2020 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "# Ένωση των δύο αρχείων\n",
    "crime_data = crime_data_2010.union(crime_data_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d51d6e2-13ec-4630-adb4-525811604f63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|   Age Group| Count|\n",
      "+------------+------+\n",
      "|      Adults|121093|\n",
      "|Young Adults| 33605|\n",
      "|    Children| 10830|\n",
      "|     Seniors|  5985|\n",
      "+------------+------+\n",
      "\n",
      "DataFrame API Time: 8.412 seconds"
     ]
    }
   ],
   "source": [
    "# Μέτρηση χρόνου για DataFrame API\n",
    "start_df = time.time()\n",
    "\n",
    "# Ξεκινάμε τη διαδικασία φιλτραρίσματος και κατηγοριοποίησης\n",
    "# Φιλτράρισμα για έγκυρες ηλικίες και περιστατικά\n",
    "filtered_data = crime_data.filter(\n",
    "    (col(\"Crm Cd Desc\").like(\"%AGGRAVATED ASSAULT%\")) &\n",
    "    (col(\"Vict Age\").isNotNull()) &\n",
    "    (col(\"Vict Age\") > 0)\n",
    ")\n",
    "\n",
    "# Κατηγοριοποίηση ηλικιακών ομάδων\n",
    "age_grouped_data = filtered_data.withColumn(\n",
    "    \"Age Group\",\n",
    "    when(col(\"Vict Age\") < 18, \"Children\")\n",
    "    .when((col(\"Vict Age\") >= 18) & (col(\"Vict Age\") <= 24), \"Young Adults\")\n",
    "    .when((col(\"Vict Age\") >= 25) & (col(\"Vict Age\") <= 64), \"Adults\")\n",
    "    .otherwise(\"Seniors\")\n",
    ")\n",
    "\n",
    "# Ομαδοποίηση και ταξινόμηση κατά ηλικιακή ομάδα\n",
    "result = age_grouped_data.groupBy(\"Age Group\").agg(count(\"*\").alias(\"Count\")).orderBy(col(\"Count\").desc())\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "result.show()\n",
    "\n",
    "end_df = time.time()\n",
    "print(f\"DataFrame API Time: {end_df - start_df:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a7530-3871-47c0-9bb9-7fc91d5c2d72",
   "metadata": {},
   "source": [
    "#### RDD API 4 executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4b34e5-eb9e-4b85-8225-4e447b288cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>4200</td><td>application_1732639283265_4140</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_4140/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-166.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_4140_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adults: 121093\n",
      "Young Adults: 33605\n",
      "Children: 10830\n",
      "Seniors: 5985\n",
      "RDD API Time: 26.141 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Δημιουργία SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query1 RDD\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Φόρτωση δεδομένων από το S3 bucket και ύστερα ένωση με union δομή ώστε να έχουμε ολα τα data σε ένα Dataframe\n",
    "crime_data_2010 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "crime_data_2020 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "# Ένωση των δύο αρχείων\n",
    "crime_data = crime_data_2010.union(crime_data_2020)\n",
    "\n",
    "# Μέτρηση χρόνου για RDD API\n",
    "start_rdd = time.time()\n",
    "\n",
    "crime_rdd = crime_data.rdd\n",
    "# Φιλτράρισμα για aggravated assault\n",
    "filtered_rdd = crime_rdd.filter(\n",
    "    lambda row: (\n",
    "        \"AGGRAVATED ASSAULT\" in row[\"Crm Cd Desc\"] and  # Έλεγχος περιγραφής εγκλήματος\n",
    "        row[\"Vict Age\"] is not None and                 # Μη-κενές ηλικίες\n",
    "        row[\"Vict Age\"] > 0                             # Θετικές ηλικίες\n",
    "    )\n",
    ")\n",
    "\n",
    "# Κατηγοριοποίηση ηλικιών και μέτρηση\n",
    "age_grouped_rdd = filtered_rdd.map(lambda row: (\n",
    "    \"Children\" if row[\"Vict Age\"] < 18 else\n",
    "    \"Young Adults\" if 18 <= row[\"Vict Age\"] <= 24 else\n",
    "    \"Adults\" if 25 <= row[\"Vict Age\"] <= 64 else\n",
    "    \"Seniors\", 1\n",
    "))\n",
    "\n",
    "# Ομαδοποίηση και ταξινόμηση\n",
    "result_rdd = age_grouped_rdd.reduceByKey(lambda a, b: a + b).sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "for group, count in result_rdd.collect():\n",
    "    print(f\"{group}: {count}\")\n",
    "\n",
    "end_rdd = time.time()\n",
    "print(f\"RDD API Time: {end_rdd - start_rdd:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409fc573-ce1a-46c1-81fd-72a1a20d0b62",
   "metadata": {},
   "source": [
    "# Query 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6257249-5486-44d5-a734-907577963cf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataframe API (Default executors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed74edb-80cc-40d6-9842-24406feb466d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------------+-------+\n",
      "|year|precinct   |closed_case_rate  |ranking|\n",
      "+----+-----------+------------------+-------+\n",
      "|2010|Rampart    |32.84713448949121 |1      |\n",
      "|2010|Olympic    |31.515289821999087|2      |\n",
      "|2010|Harbor     |29.36028339237341 |3      |\n",
      "|2011|Olympic    |35.040060090135206|1      |\n",
      "|2011|Rampart    |32.4964471814306  |2      |\n",
      "|2011|Harbor     |28.51336246316431 |3      |\n",
      "|2012|Olympic    |34.29708533302119 |1      |\n",
      "|2012|Rampart    |32.46000463714352 |2      |\n",
      "|2012|Harbor     |29.509585848956675|3      |\n",
      "|2013|Olympic    |33.58217940999398 |1      |\n",
      "|2013|Rampart    |32.1060382916053  |2      |\n",
      "|2013|Harbor     |29.723638951488557|3      |\n",
      "|2014|Van Nuys   |32.0215235281705  |1      |\n",
      "|2014|West Valley|31.49754809505847 |2      |\n",
      "|2014|Mission    |31.224939855653567|3      |\n",
      "|2015|Van Nuys   |32.265140677157845|1      |\n",
      "|2015|Mission    |30.463762673676303|2      |\n",
      "|2015|Foothill   |30.353001803658852|3      |\n",
      "|2016|Van Nuys   |32.194518462124094|1      |\n",
      "|2016|West Valley|31.40146437042384 |2      |\n",
      "|2016|Foothill   |29.908647228131645|3      |\n",
      "|2017|Van Nuys   |32.0554272517321  |1      |\n",
      "|2017|Mission    |31.055387158996968|2      |\n",
      "|2017|Foothill   |30.469700657094183|3      |\n",
      "|2018|Foothill   |30.731346958877126|1      |\n",
      "|2018|Mission    |30.727023319615913|2      |\n",
      "|2018|Van Nuys   |28.905206942590123|3      |\n",
      "|2019|Mission    |30.727411112319235|1      |\n",
      "|2019|West Valley|30.57974335472044 |2      |\n",
      "|2019|N Hollywood|29.23808669119627 |3      |\n",
      "|2020|West Valley|30.771131982204647|1      |\n",
      "|2020|Mission    |30.14974649215894 |2      |\n",
      "|2020|Harbor     |29.693486590038315|3      |\n",
      "|2021|Mission    |30.318115590092276|1      |\n",
      "|2021|West Valley|28.971087440009363|2      |\n",
      "|2021|Foothill   |27.993757094211126|3      |\n",
      "|2022|West Valley|26.536367172306498|1      |\n",
      "|2022|Harbor     |26.337538060026098|2      |\n",
      "|2022|Topanga    |26.234013317831096|3      |\n",
      "|2023|Foothill   |26.76076020122974 |1      |\n",
      "|2023|Topanga    |26.538022616453986|2      |\n",
      "|2023|Mission    |25.662731120516817|3      |\n",
      "|2024|N Hollywood|19.598528961078763|1      |\n",
      "|2024|Foothill   |18.620882188721385|2      |\n",
      "|2024|77th Street|17.586318167150694|3      |\n",
      "+----+-----------+------------------+-------+\n",
      "\n",
      "DataFrame API Time: 13.923 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Δημιουργία SparkSession\n",
    "# Ενεργοποιεί την παλαιότερη συμπεριφορά (Legacy Parser) για την ανάλυση ημερομηνιών\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query2\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Φόρτωση δεδομένων από το S3 bucket και ύστερα ένωση με union δομή ώστε να έχουμε ολα τα data σε ένα Dataframe\n",
    "crime_data_2010 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "crime_data_2020 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "# Ένωση των δύο αρχείων\n",
    "crime_data = crime_data_2010.union(crime_data_2020)\n",
    "\n",
    "from pyspark.sql.functions import col, count, sum, year, rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "start_df = time.time()\n",
    "\n",
    "# Μετατροπή DATE OCC σε timestamp\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"DATE OCC\",\n",
    "    to_timestamp(col(\"DATE OCC\"), \"MM/dd/yyyy hh:mm:ss a\")\n",
    ")\n",
    "\n",
    "# Εξαγωγή έτους από τη στήλη DATE OCC\n",
    "crime_data = crime_data.withColumn(\"year\", year(col(\"DATE OCC\")))\n",
    "\n",
    "\n",
    "# Μετονομασία της στήλης AREA NAME σε precinct\n",
    "crime_data = crime_data.withColumnRenamed(\"AREA NAME\", \"precinct\")\n",
    "\n",
    "# Σήμανση αν η τιμή ΔΕΝ είναι \"Invest Cont\" και ΔΕΝ είναι \"UNK\" (1 αν όχι, 0 αν ναι)\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"is_closed\",\n",
    "    (~(col(\"Status Desc\").isin(\"Invest Cont\", \"UNK\"))).cast(\"int\") \n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικών υποθέσεων και κλειστών υποθέσεων ανά έτος και precinct\n",
    "case_stats = crime_data.groupBy(\"year\", \"precinct\").agg(\n",
    "    count(\"*\").alias(\"total_cases\"),          # Συνολικές υποθέσεις\n",
    "    sum(\"is_closed\").alias(\"closed_cases\")   # Κλειστές υποθέσεις\n",
    ")\n",
    "\n",
    "# Υπολογισμός closed_case_rate\n",
    "case_stats = case_stats.withColumn(\n",
    "    \"closed_case_rate\",\n",
    "    (col(\"closed_cases\") / col(\"total_cases\") * 100).cast(\"double\")\n",
    ")\n",
    "\n",
    "# Δημιουργία παραθύρου για κατάταξη ανά έτος\n",
    "window_spec = Window.partitionBy(\"year\").orderBy(col(\"closed_case_rate\").desc())\n",
    "\n",
    "# Υπολογισμός κατάταξης\n",
    "ranked_data = case_stats.withColumn(\"ranking\", rank().over(window_spec))\n",
    "\n",
    "# Φιλτράρισμα για τις 3 κορυφαίες κατατάξεις κάθε χρονιάς\n",
    "top_3_precincts = ranked_data.filter(col(\"ranking\") <= 3)\n",
    "\n",
    "# Ταξινόμηση κατά έτος και ranking\n",
    "result = top_3_precincts.orderBy(\"year\", \"ranking\")\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "result.select(\"year\", \"precinct\", \"closed_case_rate\", \"ranking\").show(n=45, truncate=False)\n",
    "\n",
    "end_df = time.time()\n",
    "print(f\"DataFrame API Time: {end_df - start_df:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1390d2-2733-4b5e-a5ff-f8aa9d1d3c00",
   "metadata": {},
   "source": [
    "#### SQL API (Default executors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31a4d58a-b3ca-43dc-a234-79433f6bf005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------------+-------+\n",
      "|year|precinct   |closed_case_rate  |ranking|\n",
      "+----+-----------+------------------+-------+\n",
      "|2010|Rampart    |32.84713448949121 |1      |\n",
      "|2010|Olympic    |31.515289821999087|2      |\n",
      "|2010|Harbor     |29.36028339237341 |3      |\n",
      "|2011|Olympic    |35.040060090135206|1      |\n",
      "|2011|Rampart    |32.4964471814306  |2      |\n",
      "|2011|Harbor     |28.51336246316431 |3      |\n",
      "|2012|Olympic    |34.29708533302119 |1      |\n",
      "|2012|Rampart    |32.46000463714352 |2      |\n",
      "|2012|Harbor     |29.509585848956675|3      |\n",
      "|2013|Olympic    |33.58217940999398 |1      |\n",
      "|2013|Rampart    |32.1060382916053  |2      |\n",
      "|2013|Harbor     |29.723638951488557|3      |\n",
      "|2014|Van Nuys   |32.0215235281705  |1      |\n",
      "|2014|West Valley|31.49754809505847 |2      |\n",
      "|2014|Mission    |31.224939855653567|3      |\n",
      "|2015|Van Nuys   |32.265140677157845|1      |\n",
      "|2015|Mission    |30.463762673676303|2      |\n",
      "|2015|Foothill   |30.353001803658852|3      |\n",
      "|2016|Van Nuys   |32.194518462124094|1      |\n",
      "|2016|West Valley|31.40146437042384 |2      |\n",
      "|2016|Foothill   |29.908647228131645|3      |\n",
      "|2017|Van Nuys   |32.0554272517321  |1      |\n",
      "|2017|Mission    |31.055387158996968|2      |\n",
      "|2017|Foothill   |30.469700657094183|3      |\n",
      "|2018|Foothill   |30.731346958877126|1      |\n",
      "|2018|Mission    |30.727023319615913|2      |\n",
      "|2018|Van Nuys   |28.905206942590123|3      |\n",
      "|2019|Mission    |30.727411112319235|1      |\n",
      "|2019|West Valley|30.57974335472044 |2      |\n",
      "|2019|N Hollywood|29.23808669119627 |3      |\n",
      "|2020|West Valley|30.771131982204647|1      |\n",
      "|2020|Mission    |30.14974649215894 |2      |\n",
      "|2020|Harbor     |29.693486590038315|3      |\n",
      "|2021|Mission    |30.318115590092276|1      |\n",
      "|2021|West Valley|28.971087440009363|2      |\n",
      "|2021|Foothill   |27.993757094211126|3      |\n",
      "|2022|West Valley|26.536367172306498|1      |\n",
      "|2022|Harbor     |26.337538060026098|2      |\n",
      "|2022|Topanga    |26.234013317831096|3      |\n",
      "|2023|Foothill   |26.76076020122974 |1      |\n",
      "|2023|Topanga    |26.538022616453986|2      |\n",
      "|2023|Mission    |25.662731120516817|3      |\n",
      "|2024|N Hollywood|19.598528961078763|1      |\n",
      "|2024|Foothill   |18.620882188721385|2      |\n",
      "|2024|77th Street|17.586318167150694|3      |\n",
      "+----+-----------+------------------+-------+\n",
      "\n",
      "SQL API Execution Time: 13.536 seconds"
     ]
    }
   ],
   "source": [
    "# Φόρτωση δεδομένων από το S3 bucket και ύστερα ένωση με union δομή ώστε να έχουμε ολα τα data σε ένα Dataframe\n",
    "crime_data_2010 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "crime_data_2020 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "# Ένωση των δύο αρχείων\n",
    "crime_data = crime_data_2010.union(crime_data_2020)\n",
    "\n",
    "from pyspark.sql.functions import col, count, sum, year, rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "start_sql = time.time()\n",
    "\n",
    "# Μετατροπή DATE OCC σε timestamp\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"DATE OCC\",\n",
    "    to_timestamp(col(\"DATE OCC\"), \"MM/dd/yyyy hh:mm:ss a\")\n",
    ")\n",
    "\n",
    "# Εξαγωγή έτους από τη στήλη DATE OCC\n",
    "crime_data = crime_data.withColumn(\"year\", year(col(\"DATE OCC\")))\n",
    "\n",
    "\n",
    "# Μετονομασία της στήλης AREA NAME σε precinct\n",
    "crime_data = crime_data.withColumnRenamed(\"AREA NAME\", \"precinct\")\n",
    "\n",
    "# Σήμανση αν η τιμή ΔΕΝ είναι \"Invest Cont\" και ΔΕΝ είναι \"UNK\" (1 αν όχι, 0 αν ναι)\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"is_closed\",\n",
    "    (~(col(\"Status Desc\").isin(\"Invest Cont\", \"UNK\"))).cast(\"int\") \n",
    ")\n",
    "# Υπολογισμός συνολικών υποθέσεων και κλειστών υποθέσεων ανά έτος και precinct\n",
    "case_stats = crime_data.groupBy(\"year\", \"precinct\").agg(\n",
    "    count(\"*\").alias(\"total_cases\"),          # Συνολικές υποθέσεις\n",
    "    sum(\"is_closed\").alias(\"closed_cases\")   # Κλειστές υποθέσεις\n",
    ")\n",
    "\n",
    "# Υπολογισμός closed_case_rate\n",
    "case_stats = case_stats.withColumn(\n",
    "    \"closed_case_rate\",\n",
    "    (col(\"closed_cases\") / col(\"total_cases\") * 100).cast(\"double\")\n",
    ")\n",
    "# Δημιουργία προσωρινού πίνακα για χρήση SQL\n",
    "crime_data.createOrReplaceTempView(\"crime_data_table\")\n",
    "\n",
    "# Γράφουμε το SQL query\n",
    "query = \"\"\"\n",
    "WITH ranked_data AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        precinct,\n",
    "        (SUM(is_closed) / COUNT(*) * 100) AS closed_case_rate,\n",
    "        RANK() OVER (PARTITION BY year ORDER BY (SUM(is_closed) / COUNT(*) * 100) DESC) AS ranking\n",
    "    FROM crime_data_table\n",
    "    GROUP BY year, precinct\n",
    ")\n",
    "SELECT \n",
    "    year,\n",
    "    precinct,\n",
    "    closed_case_rate,\n",
    "    ranking\n",
    "FROM ranked_data\n",
    "WHERE ranking <= 3\n",
    "ORDER BY year, ranking\n",
    "\"\"\"\n",
    "\n",
    "# Εκτέλεση του SQL Query\n",
    "result_sql = spark.sql(query)\n",
    "\n",
    "# Εμφάνιση των αποτελεσμάτων με format παρόμοιο με την εικόνα\n",
    "result_sql.show(n=45, truncate=False)\n",
    "\n",
    "\n",
    "# Εκτύπωση χρόνου εκτέλεσης\n",
    "end_sql = time.time()\n",
    "print(f\"SQL API Execution Time: {end_sql - start_sql:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c15d4-ccf7-43e0-a2ec-50ca3d9eba0e",
   "metadata": {},
   "source": [
    "#### Paqruet & SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baddd503-2ea7-4a64-b1fe-0aa49640bf28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to write to Parquet: 28.166 seconds\n",
      "+----+-----------+------------------+-------+\n",
      "|year|precinct   |closed_case_rate  |ranking|\n",
      "+----+-----------+------------------+-------+\n",
      "|2010|Rampart    |32.84713448949121 |1      |\n",
      "|2010|Olympic    |31.515289821999087|2      |\n",
      "|2010|Harbor     |29.36028339237341 |3      |\n",
      "|2011|Olympic    |35.040060090135206|1      |\n",
      "|2011|Rampart    |32.4964471814306  |2      |\n",
      "|2011|Harbor     |28.51336246316431 |3      |\n",
      "|2012|Olympic    |34.29708533302119 |1      |\n",
      "|2012|Rampart    |32.46000463714352 |2      |\n",
      "|2012|Harbor     |29.509585848956675|3      |\n",
      "|2013|Olympic    |33.58217940999398 |1      |\n",
      "|2013|Rampart    |32.1060382916053  |2      |\n",
      "|2013|Harbor     |29.723638951488557|3      |\n",
      "|2014|Van Nuys   |32.0215235281705  |1      |\n",
      "|2014|West Valley|31.49754809505847 |2      |\n",
      "|2014|Mission    |31.224939855653567|3      |\n",
      "|2015|Van Nuys   |32.265140677157845|1      |\n",
      "|2015|Mission    |30.463762673676303|2      |\n",
      "|2015|Foothill   |30.353001803658852|3      |\n",
      "|2016|Van Nuys   |32.194518462124094|1      |\n",
      "|2016|West Valley|31.40146437042384 |2      |\n",
      "|2016|Foothill   |29.908647228131645|3      |\n",
      "|2017|Van Nuys   |32.0554272517321  |1      |\n",
      "|2017|Mission    |31.055387158996968|2      |\n",
      "|2017|Foothill   |30.469700657094183|3      |\n",
      "|2018|Foothill   |30.731346958877126|1      |\n",
      "|2018|Mission    |30.727023319615913|2      |\n",
      "|2018|Van Nuys   |28.905206942590123|3      |\n",
      "|2019|Mission    |30.727411112319235|1      |\n",
      "|2019|West Valley|30.57974335472044 |2      |\n",
      "|2019|N Hollywood|29.23808669119627 |3      |\n",
      "|2020|West Valley|30.771131982204647|1      |\n",
      "|2020|Mission    |30.14974649215894 |2      |\n",
      "|2020|Harbor     |29.693486590038315|3      |\n",
      "|2021|Mission    |30.318115590092276|1      |\n",
      "|2021|West Valley|28.971087440009363|2      |\n",
      "|2021|Foothill   |27.993757094211126|3      |\n",
      "|2022|West Valley|26.536367172306498|1      |\n",
      "|2022|Harbor     |26.337538060026098|2      |\n",
      "|2022|Topanga    |26.234013317831096|3      |\n",
      "|2023|Foothill   |26.76076020122974 |1      |\n",
      "|2023|Topanga    |26.538022616453986|2      |\n",
      "|2023|Mission    |25.662731120516817|3      |\n",
      "|2024|N Hollywood|19.598528961078763|1      |\n",
      "|2024|Foothill   |18.620882188721385|2      |\n",
      "|2024|77th Street|17.586318167150694|3      |\n",
      "+----+-----------+------------------+-------+\n",
      "\n",
      "SQL API Execution Time using Parquet: 12.324 seconds"
     ]
    }
   ],
   "source": [
    "# 1. Φόρτωση δεδομένων από τα δύο CSV αρχεία\n",
    "crime_data_2010 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "\n",
    "crime_data_2020 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "\n",
    "# 2. Ένωση των δύο DataFrames\n",
    "crime_data = crime_data_2010.union(crime_data_2020)\n",
    "\n",
    "# 3. Μετατροπή και αποθήκευση ως Parquet στο S3\n",
    "start_parquet_write = time.time()\n",
    "\n",
    "# Αποθήκευση σε μοναδικό αρχείο .parquet\n",
    "crime_data.coalesce(1).write.mode(\"overwrite\").parquet(\n",
    "    \"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\"\n",
    ")\n",
    "\n",
    "end_parquet_write = time.time()\n",
    "print(f\"Time to write to Parquet: {round(end_parquet_write - start_parquet_write, 3)} seconds\")\n",
    "\n",
    "# Διαβάζοντας από Parquet\n",
    "start_parquet_read_sql = time.time()\n",
    "\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "\n",
    "# 2. Μετατροπή DATE OCC σε timestamp (αν χρειαστεί ξανά)\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"DATE OCC\",\n",
    "    to_timestamp(col(\"DATE OCC\"), \"MM/dd/yyyy hh:mm:ss a\")\n",
    ")\n",
    "\n",
    "# 3. Εξαγωγή έτους από τη στήλη DATE OCC\n",
    "crime_data = crime_data.withColumn(\"year\", year(col(\"DATE OCC\")))\n",
    "\n",
    "# 4. Μετονομασία της στήλης AREA NAME σε precinct\n",
    "crime_data = crime_data.withColumnRenamed(\"AREA NAME\", \"precinct\")\n",
    "\n",
    "# 5. Σήμανση αν η τιμή ΔΕΝ είναι \"Invest Cont\" και ΔΕΝ είναι \"UNK\" (1 αν όχι, 0 αν ναι)\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"is_closed\",\n",
    "    (~(col(\"Status Desc\").isin(\"Invest Cont\", \"UNK\"))).cast(\"int\")\n",
    ")\n",
    "\n",
    "# 6. Δημιουργία προσωρινού πίνακα για χρήση SQL\n",
    "crime_data.createOrReplaceTempView(\"crime_data_table\")\n",
    "\n",
    "# 7. Γράφουμε το SQL Query για υπολογισμούς και κατάταξη\n",
    "query = \"\"\"\n",
    "WITH ranked_data AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        precinct,\n",
    "        (SUM(is_closed) / COUNT(*) * 100) AS closed_case_rate,\n",
    "        RANK() OVER (PARTITION BY year ORDER BY (SUM(is_closed) / COUNT(*) * 100) DESC) AS ranking\n",
    "    FROM crime_data_table\n",
    "    GROUP BY year, precinct\n",
    ")\n",
    "SELECT \n",
    "    year,\n",
    "    precinct,\n",
    "    closed_case_rate,\n",
    "    ranking\n",
    "FROM ranked_data\n",
    "WHERE ranking <= 3\n",
    "ORDER BY year, ranking\n",
    "\"\"\"\n",
    "\n",
    "# 8. Εκτέλεση του SQL Query\n",
    "result_sql = spark.sql(query)\n",
    "\n",
    "# 9. Εμφάνιση αποτελεσμάτων\n",
    "result_sql.show(n=45, truncate=False)\n",
    "\n",
    "end_parquet_read_sql = time.time()\n",
    "print(f\"SQL API Execution Time using Parquet: {round(end_parquet_read_sql - start_parquet_read_sql, 3)} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18084f9b-e142-497b-b836-5673b0a37131",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Query 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750711b-027d-491f-9c54-26d62b62329f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Broadcast Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8537d089-57e7-4f58-8b69-bdce9ff79452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (43)\n",
      "+- Project (42)\n",
      "   +- BroadcastHashJoin Inner BuildRight (41)\n",
      "      :- Project (25)\n",
      "      :  +- BroadcastHashJoin Inner BuildRight (24)\n",
      "      :     :- HashAggregate (14)\n",
      "      :     :  +- Exchange (13)\n",
      "      :     :     +- HashAggregate (12)\n",
      "      :     :        +- Project (11)\n",
      "      :     :           +- BroadcastIndexJoin (10)\n",
      "      :     :              :- Project (3)\n",
      "      :     :              :  +- Filter (2)\n",
      "      :     :              :     +- Scan parquet  (1)\n",
      "      :     :              +- SpatialIndex (9)\n",
      "      :     :                 +- Project (8)\n",
      "      :     :                    +- Filter (7)\n",
      "      :     :                       +- Generate (6)\n",
      "      :     :                          +- Filter (5)\n",
      "      :     :                             +- Scan geojson  (4)\n",
      "      :     +- BroadcastExchange (23)\n",
      "      :        +- HashAggregate (22)\n",
      "      :           +- Exchange (21)\n",
      "      :              +- HashAggregate (20)\n",
      "      :                 +- Project (19)\n",
      "      :                    +- Filter (18)\n",
      "      :                       +- Generate (17)\n",
      "      :                          +- Filter (16)\n",
      "      :                             +- Scan geojson  (15)\n",
      "      +- BroadcastExchange (40)\n",
      "         +- HashAggregate (39)\n",
      "            +- Exchange (38)\n",
      "               +- HashAggregate (37)\n",
      "                  +- Project (36)\n",
      "                     +- BroadcastHashJoin Inner BuildRight (35)\n",
      "                        :- Project (30)\n",
      "                        :  +- Filter (29)\n",
      "                        :     +- Generate (28)\n",
      "                        :        +- Filter (27)\n",
      "                        :           +- Scan geojson  (26)\n",
      "                        +- BroadcastExchange (34)\n",
      "                           +- Project (33)\n",
      "                              +- Filter (32)\n",
      "                                 +- Scan csv  (31)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [2]: [LAT#366, LON#367]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [s3://groups-bucket-dblab-905418150721/group27/Crime_Data]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#366, LON#367]\n",
      "Condition : ((((isnotnull(LAT#366) AND isnotnull(LON#367)) AND NOT (LAT#366 = 0.0)) AND NOT (LON#367 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#765]\n",
      "Input [2]: [LAT#366, LON#367]\n",
      "\n",
      "(4) Scan geojson \n",
      "Output [1]: [features#434]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(5) Filter\n",
      "Input [1]: [features#434]\n",
      "Condition : ((size(features#434, true) > 0) AND isnotnull(features#434))\n",
      "\n",
      "(6) Generate\n",
      "Input [1]: [features#434]\n",
      "Arguments: explode(features#434), false, [features#442]\n",
      "\n",
      "(7) Filter\n",
      "Input [1]: [features#442]\n",
      "Condition : ((((((isnotnull(features#442.properties.ZCTA10) AND isnotnull(features#442.properties.COMM)) AND isnotnull(cast(features#442.properties.POP_2010 as int))) AND isnotnull(cast(features#442.properties.HOUSING10 as int))) AND ((cast(features#442.properties.POP_2010 as int) > 0) AND (cast(features#442.properties.HOUSING10 as int) > 0))) OR ((cast(features#442.properties.HOUSING10 as int) = cast(features#442.properties.POP_2010 as int)) AND (cast(features#442.properties.HOUSING10 as int) < cast(features#442.properties.POP_2010 as int)))) AND (isnotnull(features#442.geometry) AND isnotnull(features#442.properties.COMM)))\n",
      "\n",
      "(8) Project\n",
      "Output [2]: [features#442.properties.COMM AS COMM#458, features#442.geometry AS geometry#445]\n",
      "Input [1]: [features#442]\n",
      "\n",
      "(9) SpatialIndex\n",
      "Arguments: geometry#445: geometry, RTREE, false, false\n",
      "\n",
      "(10) BroadcastIndexJoin\n",
      "Arguments: geom#765: geometry, RightSide, LeftSide, Inner, WITHIN\n",
      "\n",
      "(11) Project\n",
      "Output [1]: [COMM#458]\n",
      "Input [3]: [geom#765, COMM#458, geometry#445]\n",
      "\n",
      "(12) HashAggregate\n",
      "Input [1]: [COMM#458]\n",
      "Keys [1]: [COMM#458]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#1037L]\n",
      "Results [2]: [COMM#458, count#1038L]\n",
      "\n",
      "(13) Exchange\n",
      "Input [2]: [COMM#458, count#1038L]\n",
      "Arguments: hashpartitioning(COMM#458, 1000), ENSURE_REQUIREMENTS, [plan_id=335]\n",
      "\n",
      "(14) HashAggregate\n",
      "Input [2]: [COMM#458, count#1038L]\n",
      "Keys [1]: [COMM#458]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#960L]\n",
      "Results [2]: [COMM#458, count(1)#960L AS total_crimes#961L]\n",
      "\n",
      "(15) Scan geojson \n",
      "Output [1]: [features#965]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(16) Filter\n",
      "Input [1]: [features#965]\n",
      "Condition : ((size(features#965, true) > 0) AND isnotnull(features#965))\n",
      "\n",
      "(17) Generate\n",
      "Input [1]: [features#965]\n",
      "Arguments: explode(features#965), false, [features#442]\n",
      "\n",
      "(18) Filter\n",
      "Input [1]: [features#442]\n",
      "Condition : ((((((isnotnull(features#442.properties.ZCTA10) AND isnotnull(features#442.properties.COMM)) AND isnotnull(cast(features#442.properties.POP_2010 as int))) AND isnotnull(cast(features#442.properties.HOUSING10 as int))) AND ((cast(features#442.properties.POP_2010 as int) > 0) AND (cast(features#442.properties.HOUSING10 as int) > 0))) OR ((cast(features#442.properties.HOUSING10 as int) = cast(features#442.properties.POP_2010 as int)) AND (cast(features#442.properties.HOUSING10 as int) < cast(features#442.properties.POP_2010 as int)))) AND isnotnull(features#442.properties.COMM))\n",
      "\n",
      "(19) Project\n",
      "Output [2]: [features#442.properties.COMM AS COMM#975, cast(features#442.properties.POP_2010 as int) AS POP_2010#588]\n",
      "Input [1]: [features#442]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [2]: [COMM#975, POP_2010#588]\n",
      "Keys [1]: [COMM#975]\n",
      "Functions [1]: [partial_sum(POP_2010#588)]\n",
      "Aggregate Attributes [1]: [sum#1039L]\n",
      "Results [2]: [COMM#975, sum#1040L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [2]: [COMM#975, sum#1040L]\n",
      "Arguments: hashpartitioning(COMM#975, 1000), ENSURE_REQUIREMENTS, [plan_id=337]\n",
      "\n",
      "(22) HashAggregate\n",
      "Input [2]: [COMM#975, sum#1040L]\n",
      "Keys [1]: [COMM#975]\n",
      "Functions [1]: [sum(POP_2010#588)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#588)#761L]\n",
      "Results [2]: [COMM#975, sum(POP_2010#588)#761L AS POP_2010#762L]\n",
      "\n",
      "(23) BroadcastExchange\n",
      "Input [2]: [COMM#975, POP_2010#762L]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=340]\n",
      "\n",
      "(24) BroadcastHashJoin\n",
      "Left keys [1]: [COMM#458]\n",
      "Right keys [1]: [COMM#975]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(25) Project\n",
      "Output [4]: [COMM#458, total_crimes#961L, POP_2010#762L, (cast(total_crimes#961L as double) / cast(POP_2010#762L as double)) AS crimes_per_person#997]\n",
      "Input [4]: [COMM#458, total_crimes#961L, COMM#975, POP_2010#762L]\n",
      "\n",
      "(26) Scan geojson \n",
      "Output [1]: [features#1003]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(27) Filter\n",
      "Input [1]: [features#1003]\n",
      "Condition : ((size(features#1003, true) > 0) AND isnotnull(features#1003))\n",
      "\n",
      "(28) Generate\n",
      "Input [1]: [features#1003]\n",
      "Arguments: explode(features#1003), false, [features#442]\n",
      "\n",
      "(29) Filter\n",
      "Input [1]: [features#442]\n",
      "Condition : ((((((isnotnull(features#442.properties.ZCTA10) AND isnotnull(features#442.properties.COMM)) AND isnotnull(cast(features#442.properties.POP_2010 as int))) AND isnotnull(cast(features#442.properties.HOUSING10 as int))) AND ((cast(features#442.properties.POP_2010 as int) > 0) AND (cast(features#442.properties.HOUSING10 as int) > 0))) OR ((cast(features#442.properties.HOUSING10 as int) = cast(features#442.properties.POP_2010 as int)) AND (cast(features#442.properties.HOUSING10 as int) < cast(features#442.properties.POP_2010 as int)))) AND (isnotnull(features#442.properties.ZCTA10) AND isnotnull(features#442.properties.COMM)))\n",
      "\n",
      "(30) Project\n",
      "Output [4]: [features#442.properties.COMM AS COMM#1013, cast(features#442.properties.HOUSING10 as int) AS HOUSING10#615, cast(features#442.properties.POP_2010 as int) AS POP_2010#588, features#442.properties.ZCTA10 AS ZCTA10#1030]\n",
      "Input [1]: [features#442]\n",
      "\n",
      "(31) Scan csv \n",
      "Output [2]: [Zip Code#414, Estimated Median Income#416]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(32) Filter\n",
      "Input [2]: [Zip Code#414, Estimated Median Income#416]\n",
      "Condition : isnotnull(Zip Code#414)\n",
      "\n",
      "(33) Project\n",
      "Output [2]: [Zip Code#414, cast(regexp_replace(regexp_replace(Estimated Median Income#416, \\$, , 1), ,, , 1) as int) AS Estimated Median Income#579]\n",
      "Input [2]: [Zip Code#414, Estimated Median Income#416]\n",
      "\n",
      "(34) BroadcastExchange\n",
      "Input [2]: [Zip Code#414, Estimated Median Income#579]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=343]\n",
      "\n",
      "(35) BroadcastHashJoin\n",
      "Left keys [1]: [cast(ZCTA10#1030 as int)]\n",
      "Right keys [1]: [Zip Code#414]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(36) Project\n",
      "Output [4]: [COMM#1013, HOUSING10#615, POP_2010#588, Estimated Median Income#579]\n",
      "Input [6]: [COMM#1013, HOUSING10#615, POP_2010#588, ZCTA10#1030, Zip Code#414, Estimated Median Income#579]\n",
      "\n",
      "(37) HashAggregate\n",
      "Input [4]: [COMM#1013, HOUSING10#615, POP_2010#588, Estimated Median Income#579]\n",
      "Keys [1]: [COMM#1013]\n",
      "Functions [2]: [partial_sum((cast((Estimated Median Income#579 * HOUSING10#615) as double) / cast(POP_2010#588 as double))), partial_count(1)]\n",
      "Aggregate Attributes [2]: [sum#1041, count#1043L]\n",
      "Results [3]: [COMM#1013, sum#1042, count#1044L]\n",
      "\n",
      "(38) Exchange\n",
      "Input [3]: [COMM#1013, sum#1042, count#1044L]\n",
      "Arguments: hashpartitioning(COMM#1013, 1000), ENSURE_REQUIREMENTS, [plan_id=348]\n",
      "\n",
      "(39) HashAggregate\n",
      "Input [3]: [COMM#1013, sum#1042, count#1044L]\n",
      "Keys [1]: [COMM#1013]\n",
      "Functions [2]: [sum((cast((Estimated Median Income#579 * HOUSING10#615) as double) / cast(POP_2010#588 as double))), count(1)]\n",
      "Aggregate Attributes [2]: [sum((cast((Estimated Median Income#579 * HOUSING10#615) as double) / cast(POP_2010#588 as double)))#730, count(1)#731L]\n",
      "Results [2]: [COMM#1013, (sum((cast((Estimated Median Income#579 * HOUSING10#615) as double) / cast(POP_2010#588 as double)))#730 / cast(count(1)#731L as double)) AS income_per_capita#732]\n",
      "\n",
      "(40) BroadcastExchange\n",
      "Input [2]: [COMM#1013, income_per_capita#732]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=351]\n",
      "\n",
      "(41) BroadcastHashJoin\n",
      "Left keys [1]: [COMM#458]\n",
      "Right keys [1]: [COMM#1013]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(42) Project\n",
      "Output [5]: [COMM#458, total_crimes#961L, POP_2010#762L, crimes_per_person#997, income_per_capita#732]\n",
      "Input [6]: [COMM#458, total_crimes#961L, POP_2010#762L, crimes_per_person#997, COMM#1013, income_per_capita#732]\n",
      "\n",
      "(43) AdaptiveSparkPlan\n",
      "Output [5]: [COMM#458, total_crimes#961L, POP_2010#762L, crimes_per_person#997, income_per_capita#732]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "+---------------------+--------+---------------------+------------------+\n",
      "|COMM                 |POP_2010|crimes_per_person    |income_per_capita |\n",
      "+---------------------+--------+---------------------+------------------+\n",
      "|Culver City          |38878   |0.008873913267143372 |33044.84322867953 |\n",
      "|Rosewood/East Gardena|1164    |0.08676975945017182  |20167.937355132806|\n",
      "|Toluca Terrace       |1301    |0.22213681783243658  |21165.856373167484|\n",
      "|Elysian Park         |5261    |0.5675727048089717   |13927.67817806031 |\n",
      "|Longwood             |4210    |0.7273159144893112   |13451.329305491636|\n",
      "|Pico Rivera          |62797   |3.184865519053458E-5 |15655.992449320736|\n",
      "|Malibu               |12645   |7.908264136022143E-5 |67242.11498258034 |\n",
      "|Green Meadows        |19814   |1.020995255879681    |8413.214132045203 |\n",
      "|Cadillac-Corning     |6665    |0.581695423855964    |23320.81619043635 |\n",
      "|Montebello           |62495   |9.600768061444915E-5 |15640.859019687945|\n",
      "|Mid-city             |14339   |0.7106492781923426   |22234.543258056856|\n",
      "|Lincoln Heights      |31101   |0.503488633805987    |11847.252381090393|\n",
      "|Westlake Village     |8152    |1.226692836113837E-4 |44359.27168831586 |\n",
      "|Van Nuys             |85959   |0.7382473039472307   |14669.501952996081|\n",
      "|Carson               |91094   |0.002437043054427295 |22977.091884112353|\n",
      "|Agoura Hills         |20330   |2.9513034923757994E-4|45007.11862926981 |\n",
      "|Rowland Heights      |48982   |4.0831325793148504E-5|19375.50202135718 |\n",
      "|Glendale             |191540  |4.28109011172601E-4  |26710.547886055683|\n",
      "|Gramercy Place       |10361   |1.0647620886014864   |14798.096050916341|\n",
      "|Faircrest Heights    |3436    |0.7272991850989523   |23451.62285783541 |\n",
      "+---------------------+--------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time with Broadcast joins: 37.039 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from pyspark.sql.functions import col, sum, count, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Δημιουργία Spark και Sedona Context\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeoJSON Read and Process\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "income_csv = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = SedonaContext.create(spark).read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Μορφοποίηση δεδομένων\n",
    "census_2010 = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in\n",
    "     blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Καθαρισμός των δεδομένων του εισοδήματος\n",
    "income_csv = income_csv.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(regexp_replace(col(\"Estimated Median Income\"), \"\\\\$\", \"\"), \",\", \"\").cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Zip Code\",\n",
    "    col(\"Zip Code\").cast(\"int\")\n",
    ")\n",
    "# Μετατροπή της στήλης POP_2010 σε αριθμητικό τύπο\n",
    "census_2010 = census_2010.withColumn(\"POP_2010\", col(\"POP_2010\").cast(\"int\")).withColumn(\"HOUSING10\", col(\"HOUSING10\").cast(\"int\"))\n",
    "\n",
    "# Φιλτράρισμα δεδομένων\n",
    "crime_data = crime_data.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & ((col(\"LAT\") != 0) & (col(\"LON\") != 0)))\n",
    "income_csv = income_csv.filter(col(\"Zip Code\").isNotNull())\n",
    "census_2010 = census_2010.filter((col(\"ZCTA10\").isNotNull()) & (col(\"COMM\").isNotNull()) & (col(\"POP_2010\").isNotNull()) &\n",
    "    (col(\"HOUSING10\").isNotNull()) & ((col(\"POP_2010\") > 0) & (col(\"HOUSING10\") > 0)) |\n",
    "    ((col(\"HOUSING10\") == col(\"POP_2010\")) & (col(\"HOUSING10\") < col(\"POP_2010\")))\n",
    ")\n",
    "\n",
    "\n",
    "start_broad = time.time()\n",
    "\n",
    "# Join μεταξύ εισοδήματος και απογραφής\n",
    "census_income_joined = census_2010.join(\n",
    "    income_csv.hint(\"BROADCAST\"),\n",
    "    census_2010[\"ZCTA10\"] == income_csv[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικού μέσου εισοδήματος ανα άτομο ανά COMM = sum(housing*income/pop) / φορες εφαρμογής του sum\n",
    "aggregated_income_data = census_income_joined.groupBy(\"COMM\").agg(\n",
    "    (sum((col(\"Estimated Median Income\") * col(\"HOUSING10\") / col(\"POP_2010\")).cast(\"double\")) /\n",
    "     count(\"*\")).alias(\"income_per_capita\")\n",
    ")\n",
    "\n",
    "\n",
    "# Κανονικοποίηση του census_2010 για μοναδικά COMM\n",
    "census_2010_normalized = census_2010.groupBy(\"COMM\").agg(\n",
    "    sum(\"POP_2010\").alias(\"POP_2010\")\n",
    ")\n",
    "\n",
    "\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"geom\",\n",
    "    ST_Point(\"LON\", \"LAT\")  # Δημιουργία γεωμετρικών σημείων από το LON και LAT\n",
    ")\n",
    "\n",
    "# Σύνδεση crime_data με census_2010 με spatial join\n",
    "joined_df = crime_data.join(\n",
    "    census_2010.hint(\"BROADCAST\"),\n",
    "    ST_Within(crime_data[\"geom\"], census_2010[\"geometry\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικών εγκλημάτων ανά COMM\n",
    "crime_by_area = joined_df.groupBy(\"COMM\").agg(\n",
    "    count(\"*\").alias(\"total_crimes\")\n",
    ")\n",
    "\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_with_population = crime_by_area.join(\n",
    "    census_2010_normalized.hint(\"BROADCAST\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός εγκλημάτων ανά άτομο\n",
    "crime_with_population = crime_with_population.withColumn(\n",
    "    \"crimes_per_person\",\n",
    "    (col(\"total_crimes\") / col(\"POP_2010\")).cast(\"double\")\n",
    ")\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_income = crime_with_population.join(\n",
    "    aggregated_income_data.hint(\"BROADCAST\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "crime_income.explain(mode=\"formatted\")\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "crime_income.select(\"COMM\", \"POP_2010\", \"crimes_per_person\", \"income_per_capita\").show(truncate=False)\n",
    "\n",
    "end_broad = time.time()\n",
    "print(f\"Execution time with Broadcast joins: {end_broad - start_broad:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f721c2-0db8-46f8-9279-bec4dae1db81",
   "metadata": {},
   "source": [
    "#### Merge Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269458a0-cea7-493d-8eca-5d8df7a6ab37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (46)\n",
      "+- Project (45)\n",
      "   +- SortMergeJoin Inner (44)\n",
      "      :- Project (25)\n",
      "      :  +- SortMergeJoin Inner (24)\n",
      "      :     :- Sort (14)\n",
      "      :     :  +- HashAggregate (13)\n",
      "      :     :     +- Exchange (12)\n",
      "      :     :        +- HashAggregate (11)\n",
      "      :     :           +- Project (10)\n",
      "      :     :              +- RangeJoin (9)\n",
      "      :     :                 :- Project (3)\n",
      "      :     :                 :  +- Filter (2)\n",
      "      :     :                 :     +- Scan parquet  (1)\n",
      "      :     :                 +- Project (8)\n",
      "      :     :                    +- Filter (7)\n",
      "      :     :                       +- Generate (6)\n",
      "      :     :                          +- Filter (5)\n",
      "      :     :                             +- Scan geojson  (4)\n",
      "      :     +- Sort (23)\n",
      "      :        +- HashAggregate (22)\n",
      "      :           +- Exchange (21)\n",
      "      :              +- HashAggregate (20)\n",
      "      :                 +- Project (19)\n",
      "      :                    +- Filter (18)\n",
      "      :                       +- Generate (17)\n",
      "      :                          +- Filter (16)\n",
      "      :                             +- Scan geojson  (15)\n",
      "      +- Sort (43)\n",
      "         +- HashAggregate (42)\n",
      "            +- Exchange (41)\n",
      "               +- HashAggregate (40)\n",
      "                  +- Project (39)\n",
      "                     +- SortMergeJoin Inner (38)\n",
      "                        :- Sort (32)\n",
      "                        :  +- Exchange (31)\n",
      "                        :     +- Project (30)\n",
      "                        :        +- Filter (29)\n",
      "                        :           +- Generate (28)\n",
      "                        :              +- Filter (27)\n",
      "                        :                 +- Scan geojson  (26)\n",
      "                        +- Sort (37)\n",
      "                           +- Exchange (36)\n",
      "                              +- Project (35)\n",
      "                                 +- Filter (34)\n",
      "                                    +- Scan csv  (33)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [2]: [LAT#1142, LON#1143]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [s3://groups-bucket-dblab-905418150721/group27/Crime_Data]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#1142, LON#1143]\n",
      "Condition : ((((isnotnull(LAT#1142) AND isnotnull(LON#1143)) AND NOT (LAT#1142 = 0.0)) AND NOT (LON#1143 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#1541]\n",
      "Input [2]: [LAT#1142, LON#1143]\n",
      "\n",
      "(4) Scan geojson \n",
      "Output [1]: [features#1210]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(5) Filter\n",
      "Input [1]: [features#1210]\n",
      "Condition : ((size(features#1210, true) > 0) AND isnotnull(features#1210))\n",
      "\n",
      "(6) Generate\n",
      "Input [1]: [features#1210]\n",
      "Arguments: explode(features#1210), false, [features#1218]\n",
      "\n",
      "(7) Filter\n",
      "Input [1]: [features#1218]\n",
      "Condition : (((((((((isnotnull(features#1218.properties.ZCTA10) AND isnotnull(features#1218.properties.COMM)) AND isnotnull(cast(features#1218.properties.POP_2010 as int))) AND isnotnull(cast(features#1218.properties.HOUSING10 as int))) AND ((cast(features#1218.properties.POP_2010 as int) > 0) AND (cast(features#1218.properties.HOUSING10 as int) > 0))) OR ((cast(features#1218.properties.HOUSING10 as int) = cast(features#1218.properties.POP_2010 as int)) AND (cast(features#1218.properties.HOUSING10 as int) < cast(features#1218.properties.POP_2010 as int)))) AND isnotnull(features#1218.geometry)) AND isnotnull(features#1218.properties.COMM)) AND bloomfilter#1814 of [bf1814 COMM#1751 estimatedNumRows=294857] filtering [features#1218.properties.COMM]) AND bloomfilter#1813 of [bf1813 COMM#1789 estimatedNumRows=294857] filtering [features#1218.properties.COMM])\n",
      "\n",
      "(8) Project\n",
      "Output [2]: [features#1218.properties.COMM AS COMM#1234, features#1218.geometry AS geometry#1221]\n",
      "Input [1]: [features#1218]\n",
      "\n",
      "(9) RangeJoin\n",
      "Arguments: geom#1541: geometry, geometry#1221: geometry, WITHIN\n",
      "\n",
      "(10) Project\n",
      "Output [1]: [COMM#1234]\n",
      "Input [3]: [geom#1541, COMM#1234, geometry#1221]\n",
      "\n",
      "(11) HashAggregate\n",
      "Input [1]: [COMM#1234]\n",
      "Keys [1]: [COMM#1234]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#1815L]\n",
      "Results [2]: [COMM#1234, count#1816L]\n",
      "\n",
      "(12) Exchange\n",
      "Input [2]: [COMM#1234, count#1816L]\n",
      "Arguments: hashpartitioning(COMM#1234, 1000), ENSURE_REQUIREMENTS, [plan_id=1587]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [2]: [COMM#1234, count#1816L]\n",
      "Keys [1]: [COMM#1234]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#1736L]\n",
      "Results [2]: [COMM#1234, count(1)#1736L AS total_crimes#1737L]\n",
      "\n",
      "(14) Sort\n",
      "Input [2]: [COMM#1234, total_crimes#1737L]\n",
      "Arguments: [COMM#1234 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(15) Scan geojson \n",
      "Output [1]: [features#1741]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(16) Filter\n",
      "Input [1]: [features#1741]\n",
      "Condition : ((size(features#1741, true) > 0) AND isnotnull(features#1741))\n",
      "\n",
      "(17) Generate\n",
      "Input [1]: [features#1741]\n",
      "Arguments: explode(features#1741), false, [features#1218]\n",
      "\n",
      "(18) Filter\n",
      "Input [1]: [features#1218]\n",
      "Condition : ((((((isnotnull(features#1218.properties.ZCTA10) AND isnotnull(features#1218.properties.COMM)) AND isnotnull(cast(features#1218.properties.POP_2010 as int))) AND isnotnull(cast(features#1218.properties.HOUSING10 as int))) AND ((cast(features#1218.properties.POP_2010 as int) > 0) AND (cast(features#1218.properties.HOUSING10 as int) > 0))) OR ((cast(features#1218.properties.HOUSING10 as int) = cast(features#1218.properties.POP_2010 as int)) AND (cast(features#1218.properties.HOUSING10 as int) < cast(features#1218.properties.POP_2010 as int)))) AND isnotnull(features#1218.properties.COMM))\n",
      "\n",
      "(19) Project\n",
      "Output [2]: [features#1218.properties.COMM AS COMM#1751, cast(features#1218.properties.POP_2010 as int) AS POP_2010#1364]\n",
      "Input [1]: [features#1218]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [2]: [COMM#1751, POP_2010#1364]\n",
      "Keys [1]: [COMM#1751]\n",
      "Functions [1]: [partial_sum(POP_2010#1364)]\n",
      "Aggregate Attributes [1]: [sum#1817L]\n",
      "Results [2]: [COMM#1751, sum#1818L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [2]: [COMM#1751, sum#1818L]\n",
      "Arguments: hashpartitioning(COMM#1751, 1000), ENSURE_REQUIREMENTS, [plan_id=1454]\n",
      "\n",
      "(22) HashAggregate\n",
      "Input [2]: [COMM#1751, sum#1818L]\n",
      "Keys [1]: [COMM#1751]\n",
      "Functions [1]: [sum(POP_2010#1364)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#1364)#1537L]\n",
      "Results [2]: [COMM#1751, sum(POP_2010#1364)#1537L AS POP_2010#1538L]\n",
      "\n",
      "(23) Sort\n",
      "Input [2]: [COMM#1751, POP_2010#1538L]\n",
      "Arguments: [COMM#1751 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(24) SortMergeJoin\n",
      "Left keys [1]: [COMM#1234]\n",
      "Right keys [1]: [COMM#1751]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(25) Project\n",
      "Output [4]: [COMM#1234, total_crimes#1737L, POP_2010#1538L, (cast(total_crimes#1737L as double) / cast(POP_2010#1538L as double)) AS crimes_per_person#1773]\n",
      "Input [4]: [COMM#1234, total_crimes#1737L, COMM#1751, POP_2010#1538L]\n",
      "\n",
      "(26) Scan geojson \n",
      "Output [1]: [features#1779]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(27) Filter\n",
      "Input [1]: [features#1779]\n",
      "Condition : ((size(features#1779, true) > 0) AND isnotnull(features#1779))\n",
      "\n",
      "(28) Generate\n",
      "Input [1]: [features#1779]\n",
      "Arguments: explode(features#1779), false, [features#1218]\n",
      "\n",
      "(29) Filter\n",
      "Input [1]: [features#1218]\n",
      "Condition : ((((((isnotnull(features#1218.properties.ZCTA10) AND isnotnull(features#1218.properties.COMM)) AND isnotnull(cast(features#1218.properties.POP_2010 as int))) AND isnotnull(cast(features#1218.properties.HOUSING10 as int))) AND ((cast(features#1218.properties.POP_2010 as int) > 0) AND (cast(features#1218.properties.HOUSING10 as int) > 0))) OR ((cast(features#1218.properties.HOUSING10 as int) = cast(features#1218.properties.POP_2010 as int)) AND (cast(features#1218.properties.HOUSING10 as int) < cast(features#1218.properties.POP_2010 as int)))) AND (isnotnull(features#1218.properties.ZCTA10) AND isnotnull(features#1218.properties.COMM)))\n",
      "\n",
      "(30) Project\n",
      "Output [4]: [features#1218.properties.COMM AS COMM#1789, cast(features#1218.properties.HOUSING10 as int) AS HOUSING10#1391, cast(features#1218.properties.POP_2010 as int) AS POP_2010#1364, features#1218.properties.ZCTA10 AS ZCTA10#1806]\n",
      "Input [1]: [features#1218]\n",
      "\n",
      "(31) Exchange\n",
      "Input [4]: [COMM#1789, HOUSING10#1391, POP_2010#1364, ZCTA10#1806]\n",
      "Arguments: hashpartitioning(cast(ZCTA10#1806 as int), 1000), ENSURE_REQUIREMENTS, [plan_id=1463]\n",
      "\n",
      "(32) Sort\n",
      "Input [4]: [COMM#1789, HOUSING10#1391, POP_2010#1364, ZCTA10#1806]\n",
      "Arguments: [cast(ZCTA10#1806 as int) ASC NULLS FIRST], false, 0\n",
      "\n",
      "(33) Scan csv \n",
      "Output [2]: [Zip Code#1190, Estimated Median Income#1192]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(34) Filter\n",
      "Input [2]: [Zip Code#1190, Estimated Median Income#1192]\n",
      "Condition : isnotnull(Zip Code#1190)\n",
      "\n",
      "(35) Project\n",
      "Output [2]: [Zip Code#1190, cast(regexp_replace(regexp_replace(Estimated Median Income#1192, \\$, , 1), ,, , 1) as int) AS Estimated Median Income#1355]\n",
      "Input [2]: [Zip Code#1190, Estimated Median Income#1192]\n",
      "\n",
      "(36) Exchange\n",
      "Input [2]: [Zip Code#1190, Estimated Median Income#1355]\n",
      "Arguments: hashpartitioning(Zip Code#1190, 1000), ENSURE_REQUIREMENTS, [plan_id=1464]\n",
      "\n",
      "(37) Sort\n",
      "Input [2]: [Zip Code#1190, Estimated Median Income#1355]\n",
      "Arguments: [Zip Code#1190 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(38) SortMergeJoin\n",
      "Left keys [1]: [cast(ZCTA10#1806 as int)]\n",
      "Right keys [1]: [Zip Code#1190]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(39) Project\n",
      "Output [4]: [COMM#1789, HOUSING10#1391, POP_2010#1364, Estimated Median Income#1355]\n",
      "Input [6]: [COMM#1789, HOUSING10#1391, POP_2010#1364, ZCTA10#1806, Zip Code#1190, Estimated Median Income#1355]\n",
      "\n",
      "(40) HashAggregate\n",
      "Input [4]: [COMM#1789, HOUSING10#1391, POP_2010#1364, Estimated Median Income#1355]\n",
      "Keys [1]: [COMM#1789]\n",
      "Functions [2]: [partial_sum((cast((Estimated Median Income#1355 * HOUSING10#1391) as double) / cast(POP_2010#1364 as double))), partial_count(1)]\n",
      "Aggregate Attributes [2]: [sum#1819, count#1821L]\n",
      "Results [3]: [COMM#1789, sum#1820, count#1822L]\n",
      "\n",
      "(41) Exchange\n",
      "Input [3]: [COMM#1789, sum#1820, count#1822L]\n",
      "Arguments: hashpartitioning(COMM#1789, 1000), ENSURE_REQUIREMENTS, [plan_id=1471]\n",
      "\n",
      "(42) HashAggregate\n",
      "Input [3]: [COMM#1789, sum#1820, count#1822L]\n",
      "Keys [1]: [COMM#1789]\n",
      "Functions [2]: [sum((cast((Estimated Median Income#1355 * HOUSING10#1391) as double) / cast(POP_2010#1364 as double))), count(1)]\n",
      "Aggregate Attributes [2]: [sum((cast((Estimated Median Income#1355 * HOUSING10#1391) as double) / cast(POP_2010#1364 as double)))#1506, count(1)#1507L]\n",
      "Results [2]: [COMM#1789, (sum((cast((Estimated Median Income#1355 * HOUSING10#1391) as double) / cast(POP_2010#1364 as double)))#1506 / cast(count(1)#1507L as double)) AS income_per_capita#1508]\n",
      "\n",
      "(43) Sort\n",
      "Input [2]: [COMM#1789, income_per_capita#1508]\n",
      "Arguments: [COMM#1789 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(44) SortMergeJoin\n",
      "Left keys [1]: [COMM#1234]\n",
      "Right keys [1]: [COMM#1789]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(45) Project\n",
      "Output [5]: [COMM#1234, total_crimes#1737L, POP_2010#1538L, crimes_per_person#1773, income_per_capita#1508]\n",
      "Input [6]: [COMM#1234, total_crimes#1737L, POP_2010#1538L, crimes_per_person#1773, COMM#1789, income_per_capita#1508]\n",
      "\n",
      "(46) AdaptiveSparkPlan\n",
      "Output [5]: [COMM#1234, total_crimes#1737L, POP_2010#1538L, crimes_per_person#1773, income_per_capita#1508]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "===== Subqueries =====\n",
      "\n",
      "Subquery:1 Hosting operator id = 7 Hosting Expression = bloomfilter#1814 of [bf1814 COMM#1751 estimatedNumRows=294857] filtering [features#1218.properties.COMM]\n",
      "OutputAdapter (55)\n",
      "+- AdaptiveSparkPlan (54)\n",
      "   +- Exchange (53)\n",
      "      +- HashAggregate (52)\n",
      "         +- Project (51)\n",
      "            +- Filter (50)\n",
      "               +- Generate (49)\n",
      "                  +- Filter (48)\n",
      "                     +- Scan geojson  (47)\n",
      "\n",
      "\n",
      "(47) Scan geojson \n",
      "Output [1]: [features#1741]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(48) Filter\n",
      "Input [1]: [features#1741]\n",
      "Condition : ((size(features#1741, true) > 0) AND isnotnull(features#1741))\n",
      "\n",
      "(49) Generate\n",
      "Input [1]: [features#1741]\n",
      "Arguments: explode(features#1741), false, [features#1218]\n",
      "\n",
      "(50) Filter\n",
      "Input [1]: [features#1218]\n",
      "Condition : ((((((isnotnull(features#1218.properties.ZCTA10) AND isnotnull(features#1218.properties.COMM)) AND isnotnull(cast(features#1218.properties.POP_2010 as int))) AND isnotnull(cast(features#1218.properties.HOUSING10 as int))) AND ((cast(features#1218.properties.POP_2010 as int) > 0) AND (cast(features#1218.properties.HOUSING10 as int) > 0))) OR ((cast(features#1218.properties.HOUSING10 as int) = cast(features#1218.properties.POP_2010 as int)) AND (cast(features#1218.properties.HOUSING10 as int) < cast(features#1218.properties.POP_2010 as int)))) AND isnotnull(features#1218.properties.COMM))\n",
      "\n",
      "(51) Project\n",
      "Output [2]: [features#1218.properties.COMM AS COMM#1751, cast(features#1218.properties.POP_2010 as int) AS POP_2010#1364]\n",
      "Input [1]: [features#1218]\n",
      "\n",
      "(52) HashAggregate\n",
      "Input [2]: [COMM#1751, POP_2010#1364]\n",
      "Keys [1]: [COMM#1751]\n",
      "Functions [1]: [partial_sum(POP_2010#1364)]\n",
      "Aggregate Attributes [1]: [sum#1817L]\n",
      "Results [2]: [COMM#1751, sum#1818L]\n",
      "\n",
      "(53) Exchange\n",
      "Input [2]: [COMM#1751, sum#1818L]\n",
      "Arguments: hashpartitioning(COMM#1751, 1000), ENSURE_REQUIREMENTS, [plan_id=1569]\n",
      "\n",
      "(54) AdaptiveSparkPlan\n",
      "Output [2]: [COMM#1751, sum#1818L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(55) OutputAdapter\n",
      "Output [2]: [COMM#1751, sum#1818L]\n",
      "\n",
      "Subquery:2 Hosting operator id = 7 Hosting Expression = bloomfilter#1813 of [bf1813 COMM#1789 estimatedNumRows=294857] filtering [features#1218.properties.COMM]\n",
      "OutputAdapter (63)\n",
      "+- AdaptiveSparkPlan (62)\n",
      "   +- Exchange (61)\n",
      "      +- Project (60)\n",
      "         +- Filter (59)\n",
      "            +- Generate (58)\n",
      "               +- Filter (57)\n",
      "                  +- Scan geojson  (56)\n",
      "\n",
      "\n",
      "(56) Scan geojson \n",
      "Output [1]: [features#1779]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(57) Filter\n",
      "Input [1]: [features#1779]\n",
      "Condition : ((size(features#1779, true) > 0) AND isnotnull(features#1779))\n",
      "\n",
      "(58) Generate\n",
      "Input [1]: [features#1779]\n",
      "Arguments: explode(features#1779), false, [features#1218]\n",
      "\n",
      "(59) Filter\n",
      "Input [1]: [features#1218]\n",
      "Condition : ((((((isnotnull(features#1218.properties.ZCTA10) AND isnotnull(features#1218.properties.COMM)) AND isnotnull(cast(features#1218.properties.POP_2010 as int))) AND isnotnull(cast(features#1218.properties.HOUSING10 as int))) AND ((cast(features#1218.properties.POP_2010 as int) > 0) AND (cast(features#1218.properties.HOUSING10 as int) > 0))) OR ((cast(features#1218.properties.HOUSING10 as int) = cast(features#1218.properties.POP_2010 as int)) AND (cast(features#1218.properties.HOUSING10 as int) < cast(features#1218.properties.POP_2010 as int)))) AND (isnotnull(features#1218.properties.ZCTA10) AND isnotnull(features#1218.properties.COMM)))\n",
      "\n",
      "(60) Project\n",
      "Output [4]: [features#1218.properties.COMM AS COMM#1789, cast(features#1218.properties.HOUSING10 as int) AS HOUSING10#1391, cast(features#1218.properties.POP_2010 as int) AS POP_2010#1364, features#1218.properties.ZCTA10 AS ZCTA10#1806]\n",
      "Input [1]: [features#1218]\n",
      "\n",
      "(61) Exchange\n",
      "Input [4]: [COMM#1789, HOUSING10#1391, POP_2010#1364, ZCTA10#1806]\n",
      "Arguments: hashpartitioning(cast(ZCTA10#1806 as int), 1000), ENSURE_REQUIREMENTS, [plan_id=1578]\n",
      "\n",
      "(62) AdaptiveSparkPlan\n",
      "Output [4]: [COMM#1789, HOUSING10#1391, POP_2010#1364, ZCTA10#1806]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(63) OutputAdapter\n",
      "Output [4]: [COMM#1789, HOUSING10#1391, POP_2010#1364, ZCTA10#1806]\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------+--------+---------------------+------------------+\n",
      "|COMM                   |POP_2010|crimes_per_person    |income_per_capita |\n",
      "+-----------------------+--------+---------------------+------------------+\n",
      "|                       |25919   |1.5432694162583434E-4|30529.41686661653 |\n",
      "|Acton                  |8031    |1.2451749470800648E-4|45528.690643954316|\n",
      "|Adams-Normandie        |7842    |0.7148686559551135   |9116.014490748246 |\n",
      "|Agoura Hills           |20330   |2.9513034923757994E-4|45007.11862926981 |\n",
      "|Alhambra               |83015   |6.26392820574595E-4  |19963.159550474433|\n",
      "|Alsace                 |11728   |0.5416098226466576   |12321.250979140943|\n",
      "|Altadena               |42777   |2.3377048413867265E-5|32502.406454911932|\n",
      "|Anaverde               |1491    |0.0026827632461435278|31545.85414769332 |\n",
      "|Angeles National Forest|1199    |0.005838198498748957 |39763.033993919875|\n",
      "|Angelino Heights       |2374    |0.5732940185341197   |20765.58441212619 |\n",
      "|Arcadia                |63924   |3.1287153494775044E-5|28646.325351369484|\n",
      "|Arleta                 |32876   |0.4264509064363061   |12148.380761908873|\n",
      "|Athens Village         |4992    |0.002003205128205128 |10343.72024313496 |\n",
      "|Athens-Westmont        |40581   |0.004608067814987309 |11434.674999924757|\n",
      "|Atwater Village        |14099   |0.5288318320448259   |27898.266443281722|\n",
      "|Avalon                 |3728    |0.001609442060085837 |75504.19912417556 |\n",
      "|Azusa                  |60683   |4.943723942455053E-5 |17849.050952097405|\n",
      "|Baldwin Hills          |28635   |0.9950061114021302   |16933.09038669228 |\n",
      "|Bel Air                |8261    |0.39922527539038855  |70127.61192200884 |\n",
      "|Bell Gardens           |42071   |2.1392408072068645E-4|9634.467062574844 |\n",
      "+-----------------------+--------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time with Merge joins: 49.049 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from pyspark.sql.functions import col, sum, count, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Δημιουργία Spark και Sedona Context\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeoJSON Read and Process\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "income_csv = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = SedonaContext.create(spark).read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Μορφοποίηση δεδομένων\n",
    "census_2010 = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in\n",
    "     blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Καθαρισμός των δεδομένων του εισοδήματος\n",
    "income_csv = income_csv.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(regexp_replace(col(\"Estimated Median Income\"), \"\\\\$\", \"\"), \",\", \"\").cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Zip Code\",\n",
    "    col(\"Zip Code\").cast(\"int\")\n",
    ")\n",
    "# Μετατροπή της στήλης POP_2010 σε αριθμητικό τύπο\n",
    "census_2010 = census_2010.withColumn(\"POP_2010\", col(\"POP_2010\").cast(\"int\")).withColumn(\"HOUSING10\", col(\"HOUSING10\").cast(\"int\"))\n",
    "\n",
    "# Φιλτράρισμα δεδομένων\n",
    "crime_data = crime_data.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & ((col(\"LAT\") != 0) & (col(\"LON\") != 0)))\n",
    "income_csv = income_csv.filter(col(\"Zip Code\").isNotNull())\n",
    "census_2010 = census_2010.filter((col(\"ZCTA10\").isNotNull()) & (col(\"COMM\").isNotNull()) & (col(\"POP_2010\").isNotNull()) &\n",
    "    (col(\"HOUSING10\").isNotNull()) & ((col(\"POP_2010\") > 0) & (col(\"HOUSING10\") > 0)) |\n",
    "    ((col(\"HOUSING10\") == col(\"POP_2010\")) & (col(\"HOUSING10\") < col(\"POP_2010\")))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "start_merge = time.time()\n",
    "# Join μεταξύ εισοδήματος και απογραφής\n",
    "census_income_joined = census_2010.join(\n",
    "    income_csv.hint(\"MERGE\"),\n",
    "    census_2010[\"ZCTA10\"] == income_csv[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικού μέσου εισοδήματος ανα άτομο ανά COMM = sum(housing*income/pop) / φορες εφαρμογής του sum\n",
    "aggregated_income_data = census_income_joined.groupBy(\"COMM\").agg(\n",
    "    (sum((col(\"Estimated Median Income\") * col(\"HOUSING10\") / col(\"POP_2010\")).cast(\"double\")) /\n",
    "     count(\"*\")).alias(\"income_per_capita\")\n",
    ")\n",
    "\n",
    "\n",
    "# Κανονικοποίηση του census_2010 για μοναδικά COMM\n",
    "census_2010_normalized = census_2010.groupBy(\"COMM\").agg(\n",
    "    sum(\"POP_2010\").alias(\"POP_2010\")\n",
    ")\n",
    "\n",
    "# Φόρτωση δεδομένων εγκλημάτων\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"geom\",\n",
    "    ST_Point(\"LON\", \"LAT\")  # Δημιουργία γεωμετρικών σημείων από το LON και LAT\n",
    ")\n",
    "\n",
    "# Σύνδεση crime_data με census_2010 με spatial join\n",
    "joined_df = crime_data.join(\n",
    "    census_2010.hint(\"MERGE\"),\n",
    "    ST_Within(crime_data[\"geom\"], census_2010[\"geometry\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικών εγκλημάτων ανά COMM\n",
    "crime_by_area = joined_df.groupBy(\"COMM\").agg(\n",
    "    count(\"*\").alias(\"total_crimes\")\n",
    ")\n",
    "\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_with_population = crime_by_area.join(\n",
    "    census_2010_normalized.hint(\"MERGE\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός εγκλημάτων ανά άτομο\n",
    "crime_with_population = crime_with_population.withColumn(\n",
    "    \"crimes_per_person\",\n",
    "    (col(\"total_crimes\") / col(\"POP_2010\")).cast(\"double\")\n",
    ")\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_income = crime_with_population.join(\n",
    "    aggregated_income_data.hint(\"MERGE\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "crime_income.explain(mode=\"formatted\")\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "crime_income.select(\"COMM\", \"POP_2010\", \"crimes_per_person\", \"income_per_capita\").show(truncate=False)\n",
    "end_merge = time.time()\n",
    "print(f\"Execution time with Merge joins: {end_merge - start_merge:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ad6a1-25af-47bc-9a2e-cce3c772724f",
   "metadata": {},
   "source": [
    "#### SHUFFLE_HASH joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b752d5-9f71-4493-afef-2683c8eb306d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (41)\n",
      "+- Project (40)\n",
      "   +- ShuffledHashJoin Inner BuildRight (39)\n",
      "      :- Project (23)\n",
      "      :  +- ShuffledHashJoin Inner BuildRight (22)\n",
      "      :     :- HashAggregate (13)\n",
      "      :     :  +- Exchange (12)\n",
      "      :     :     +- HashAggregate (11)\n",
      "      :     :        +- Project (10)\n",
      "      :     :           +- RangeJoin (9)\n",
      "      :     :              :- Project (3)\n",
      "      :     :              :  +- Filter (2)\n",
      "      :     :              :     +- Scan parquet  (1)\n",
      "      :     :              +- Project (8)\n",
      "      :     :                 +- Filter (7)\n",
      "      :     :                    +- Generate (6)\n",
      "      :     :                       +- Filter (5)\n",
      "      :     :                          +- Scan geojson  (4)\n",
      "      :     +- HashAggregate (21)\n",
      "      :        +- Exchange (20)\n",
      "      :           +- HashAggregate (19)\n",
      "      :              +- Project (18)\n",
      "      :                 +- Filter (17)\n",
      "      :                    +- Generate (16)\n",
      "      :                       +- Filter (15)\n",
      "      :                          +- Scan geojson  (14)\n",
      "      +- HashAggregate (38)\n",
      "         +- Exchange (37)\n",
      "            +- HashAggregate (36)\n",
      "               +- Project (35)\n",
      "                  +- ShuffledHashJoin Inner BuildRight (34)\n",
      "                     :- Exchange (29)\n",
      "                     :  +- Project (28)\n",
      "                     :     +- Filter (27)\n",
      "                     :        +- Generate (26)\n",
      "                     :           +- Filter (25)\n",
      "                     :              +- Scan geojson  (24)\n",
      "                     +- Exchange (33)\n",
      "                        +- Project (32)\n",
      "                           +- Filter (31)\n",
      "                              +- Scan csv  (30)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [2]: [LAT#1931, LON#1932]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [s3://groups-bucket-dblab-905418150721/group27/Crime_Data]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#1931, LON#1932]\n",
      "Condition : ((((isnotnull(LAT#1931) AND isnotnull(LON#1932)) AND NOT (LAT#1931 = 0.0)) AND NOT (LON#1932 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#2330]\n",
      "Input [2]: [LAT#1931, LON#1932]\n",
      "\n",
      "(4) Scan geojson \n",
      "Output [1]: [features#1999]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(5) Filter\n",
      "Input [1]: [features#1999]\n",
      "Condition : ((size(features#1999, true) > 0) AND isnotnull(features#1999))\n",
      "\n",
      "(6) Generate\n",
      "Input [1]: [features#1999]\n",
      "Arguments: explode(features#1999), false, [features#2007]\n",
      "\n",
      "(7) Filter\n",
      "Input [1]: [features#2007]\n",
      "Condition : (((((((((isnotnull(features#2007.properties.ZCTA10) AND isnotnull(features#2007.properties.COMM)) AND isnotnull(cast(features#2007.properties.POP_2010 as int))) AND isnotnull(cast(features#2007.properties.HOUSING10 as int))) AND ((cast(features#2007.properties.POP_2010 as int) > 0) AND (cast(features#2007.properties.HOUSING10 as int) > 0))) OR ((cast(features#2007.properties.HOUSING10 as int) = cast(features#2007.properties.POP_2010 as int)) AND (cast(features#2007.properties.HOUSING10 as int) < cast(features#2007.properties.POP_2010 as int)))) AND isnotnull(features#2007.geometry)) AND isnotnull(features#2007.properties.COMM)) AND bloomfilter#2603 of [bf2603 COMM#2540 estimatedNumRows=294857] filtering [features#2007.properties.COMM]) AND bloomfilter#2602 of [bf2602 COMM#2578 estimatedNumRows=294857] filtering [features#2007.properties.COMM])\n",
      "\n",
      "(8) Project\n",
      "Output [2]: [features#2007.properties.COMM AS COMM#2023, features#2007.geometry AS geometry#2010]\n",
      "Input [1]: [features#2007]\n",
      "\n",
      "(9) RangeJoin\n",
      "Arguments: geom#2330: geometry, geometry#2010: geometry, WITHIN\n",
      "\n",
      "(10) Project\n",
      "Output [1]: [COMM#2023]\n",
      "Input [3]: [geom#2330, COMM#2023, geometry#2010]\n",
      "\n",
      "(11) HashAggregate\n",
      "Input [1]: [COMM#2023]\n",
      "Keys [1]: [COMM#2023]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#2604L]\n",
      "Results [2]: [COMM#2023, count#2605L]\n",
      "\n",
      "(12) Exchange\n",
      "Input [2]: [COMM#2023, count#2605L]\n",
      "Arguments: hashpartitioning(COMM#2023, 1000), ENSURE_REQUIREMENTS, [plan_id=3126]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [2]: [COMM#2023, count#2605L]\n",
      "Keys [1]: [COMM#2023]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#2525L]\n",
      "Results [2]: [COMM#2023, count(1)#2525L AS total_crimes#2526L]\n",
      "\n",
      "(14) Scan geojson \n",
      "Output [1]: [features#2530]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(15) Filter\n",
      "Input [1]: [features#2530]\n",
      "Condition : ((size(features#2530, true) > 0) AND isnotnull(features#2530))\n",
      "\n",
      "(16) Generate\n",
      "Input [1]: [features#2530]\n",
      "Arguments: explode(features#2530), false, [features#2007]\n",
      "\n",
      "(17) Filter\n",
      "Input [1]: [features#2007]\n",
      "Condition : ((((((isnotnull(features#2007.properties.ZCTA10) AND isnotnull(features#2007.properties.COMM)) AND isnotnull(cast(features#2007.properties.POP_2010 as int))) AND isnotnull(cast(features#2007.properties.HOUSING10 as int))) AND ((cast(features#2007.properties.POP_2010 as int) > 0) AND (cast(features#2007.properties.HOUSING10 as int) > 0))) OR ((cast(features#2007.properties.HOUSING10 as int) = cast(features#2007.properties.POP_2010 as int)) AND (cast(features#2007.properties.HOUSING10 as int) < cast(features#2007.properties.POP_2010 as int)))) AND isnotnull(features#2007.properties.COMM))\n",
      "\n",
      "(18) Project\n",
      "Output [2]: [features#2007.properties.COMM AS COMM#2540, cast(features#2007.properties.POP_2010 as int) AS POP_2010#2153]\n",
      "Input [1]: [features#2007]\n",
      "\n",
      "(19) HashAggregate\n",
      "Input [2]: [COMM#2540, POP_2010#2153]\n",
      "Keys [1]: [COMM#2540]\n",
      "Functions [1]: [partial_sum(POP_2010#2153)]\n",
      "Aggregate Attributes [1]: [sum#2606L]\n",
      "Results [2]: [COMM#2540, sum#2607L]\n",
      "\n",
      "(20) Exchange\n",
      "Input [2]: [COMM#2540, sum#2607L]\n",
      "Arguments: hashpartitioning(COMM#2540, 1000), ENSURE_REQUIREMENTS, [plan_id=3004]\n",
      "\n",
      "(21) HashAggregate\n",
      "Input [2]: [COMM#2540, sum#2607L]\n",
      "Keys [1]: [COMM#2540]\n",
      "Functions [1]: [sum(POP_2010#2153)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#2153)#2326L]\n",
      "Results [2]: [COMM#2540, sum(POP_2010#2153)#2326L AS POP_2010#2327L]\n",
      "\n",
      "(22) ShuffledHashJoin\n",
      "Left keys [1]: [COMM#2023]\n",
      "Right keys [1]: [COMM#2540]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(23) Project\n",
      "Output [4]: [COMM#2023, total_crimes#2526L, POP_2010#2327L, (cast(total_crimes#2526L as double) / cast(POP_2010#2327L as double)) AS crimes_per_person#2562]\n",
      "Input [4]: [COMM#2023, total_crimes#2526L, COMM#2540, POP_2010#2327L]\n",
      "\n",
      "(24) Scan geojson \n",
      "Output [1]: [features#2568]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(25) Filter\n",
      "Input [1]: [features#2568]\n",
      "Condition : ((size(features#2568, true) > 0) AND isnotnull(features#2568))\n",
      "\n",
      "(26) Generate\n",
      "Input [1]: [features#2568]\n",
      "Arguments: explode(features#2568), false, [features#2007]\n",
      "\n",
      "(27) Filter\n",
      "Input [1]: [features#2007]\n",
      "Condition : ((((((isnotnull(features#2007.properties.ZCTA10) AND isnotnull(features#2007.properties.COMM)) AND isnotnull(cast(features#2007.properties.POP_2010 as int))) AND isnotnull(cast(features#2007.properties.HOUSING10 as int))) AND ((cast(features#2007.properties.POP_2010 as int) > 0) AND (cast(features#2007.properties.HOUSING10 as int) > 0))) OR ((cast(features#2007.properties.HOUSING10 as int) = cast(features#2007.properties.POP_2010 as int)) AND (cast(features#2007.properties.HOUSING10 as int) < cast(features#2007.properties.POP_2010 as int)))) AND (isnotnull(features#2007.properties.ZCTA10) AND isnotnull(features#2007.properties.COMM)))\n",
      "\n",
      "(28) Project\n",
      "Output [4]: [features#2007.properties.COMM AS COMM#2578, cast(features#2007.properties.HOUSING10 as int) AS HOUSING10#2180, cast(features#2007.properties.POP_2010 as int) AS POP_2010#2153, features#2007.properties.ZCTA10 AS ZCTA10#2595]\n",
      "Input [1]: [features#2007]\n",
      "\n",
      "(29) Exchange\n",
      "Input [4]: [COMM#2578, HOUSING10#2180, POP_2010#2153, ZCTA10#2595]\n",
      "Arguments: hashpartitioning(cast(ZCTA10#2595 as int), 1000), ENSURE_REQUIREMENTS, [plan_id=3010]\n",
      "\n",
      "(30) Scan csv \n",
      "Output [2]: [Zip Code#1979, Estimated Median Income#1981]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(31) Filter\n",
      "Input [2]: [Zip Code#1979, Estimated Median Income#1981]\n",
      "Condition : isnotnull(Zip Code#1979)\n",
      "\n",
      "(32) Project\n",
      "Output [2]: [Zip Code#1979, cast(regexp_replace(regexp_replace(Estimated Median Income#1981, \\$, , 1), ,, , 1) as int) AS Estimated Median Income#2144]\n",
      "Input [2]: [Zip Code#1979, Estimated Median Income#1981]\n",
      "\n",
      "(33) Exchange\n",
      "Input [2]: [Zip Code#1979, Estimated Median Income#2144]\n",
      "Arguments: hashpartitioning(Zip Code#1979, 1000), ENSURE_REQUIREMENTS, [plan_id=3011]\n",
      "\n",
      "(34) ShuffledHashJoin\n",
      "Left keys [1]: [cast(ZCTA10#2595 as int)]\n",
      "Right keys [1]: [Zip Code#1979]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(35) Project\n",
      "Output [4]: [COMM#2578, HOUSING10#2180, POP_2010#2153, Estimated Median Income#2144]\n",
      "Input [6]: [COMM#2578, HOUSING10#2180, POP_2010#2153, ZCTA10#2595, Zip Code#1979, Estimated Median Income#2144]\n",
      "\n",
      "(36) HashAggregate\n",
      "Input [4]: [COMM#2578, HOUSING10#2180, POP_2010#2153, Estimated Median Income#2144]\n",
      "Keys [1]: [COMM#2578]\n",
      "Functions [2]: [partial_sum((cast((Estimated Median Income#2144 * HOUSING10#2180) as double) / cast(POP_2010#2153 as double))), partial_count(1)]\n",
      "Aggregate Attributes [2]: [sum#2608, count#2610L]\n",
      "Results [3]: [COMM#2578, sum#2609, count#2611L]\n",
      "\n",
      "(37) Exchange\n",
      "Input [3]: [COMM#2578, sum#2609, count#2611L]\n",
      "Arguments: hashpartitioning(COMM#2578, 1000), ENSURE_REQUIREMENTS, [plan_id=3016]\n",
      "\n",
      "(38) HashAggregate\n",
      "Input [3]: [COMM#2578, sum#2609, count#2611L]\n",
      "Keys [1]: [COMM#2578]\n",
      "Functions [2]: [sum((cast((Estimated Median Income#2144 * HOUSING10#2180) as double) / cast(POP_2010#2153 as double))), count(1)]\n",
      "Aggregate Attributes [2]: [sum((cast((Estimated Median Income#2144 * HOUSING10#2180) as double) / cast(POP_2010#2153 as double)))#2295, count(1)#2296L]\n",
      "Results [2]: [COMM#2578, (sum((cast((Estimated Median Income#2144 * HOUSING10#2180) as double) / cast(POP_2010#2153 as double)))#2295 / cast(count(1)#2296L as double)) AS income_per_capita#2297]\n",
      "\n",
      "(39) ShuffledHashJoin\n",
      "Left keys [1]: [COMM#2023]\n",
      "Right keys [1]: [COMM#2578]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(40) Project\n",
      "Output [5]: [COMM#2023, total_crimes#2526L, POP_2010#2327L, crimes_per_person#2562, income_per_capita#2297]\n",
      "Input [6]: [COMM#2023, total_crimes#2526L, POP_2010#2327L, crimes_per_person#2562, COMM#2578, income_per_capita#2297]\n",
      "\n",
      "(41) AdaptiveSparkPlan\n",
      "Output [5]: [COMM#2023, total_crimes#2526L, POP_2010#2327L, crimes_per_person#2562, income_per_capita#2297]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "===== Subqueries =====\n",
      "\n",
      "Subquery:1 Hosting operator id = 7 Hosting Expression = bloomfilter#2603 of [bf2603 COMM#2540 estimatedNumRows=294857] filtering [features#2007.properties.COMM]\n",
      "OutputAdapter (50)\n",
      "+- AdaptiveSparkPlan (49)\n",
      "   +- Exchange (48)\n",
      "      +- HashAggregate (47)\n",
      "         +- Project (46)\n",
      "            +- Filter (45)\n",
      "               +- Generate (44)\n",
      "                  +- Filter (43)\n",
      "                     +- Scan geojson  (42)\n",
      "\n",
      "\n",
      "(42) Scan geojson \n",
      "Output [1]: [features#2530]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(43) Filter\n",
      "Input [1]: [features#2530]\n",
      "Condition : ((size(features#2530, true) > 0) AND isnotnull(features#2530))\n",
      "\n",
      "(44) Generate\n",
      "Input [1]: [features#2530]\n",
      "Arguments: explode(features#2530), false, [features#2007]\n",
      "\n",
      "(45) Filter\n",
      "Input [1]: [features#2007]\n",
      "Condition : ((((((isnotnull(features#2007.properties.ZCTA10) AND isnotnull(features#2007.properties.COMM)) AND isnotnull(cast(features#2007.properties.POP_2010 as int))) AND isnotnull(cast(features#2007.properties.HOUSING10 as int))) AND ((cast(features#2007.properties.POP_2010 as int) > 0) AND (cast(features#2007.properties.HOUSING10 as int) > 0))) OR ((cast(features#2007.properties.HOUSING10 as int) = cast(features#2007.properties.POP_2010 as int)) AND (cast(features#2007.properties.HOUSING10 as int) < cast(features#2007.properties.POP_2010 as int)))) AND isnotnull(features#2007.properties.COMM))\n",
      "\n",
      "(46) Project\n",
      "Output [2]: [features#2007.properties.COMM AS COMM#2540, cast(features#2007.properties.POP_2010 as int) AS POP_2010#2153]\n",
      "Input [1]: [features#2007]\n",
      "\n",
      "(47) HashAggregate\n",
      "Input [2]: [COMM#2540, POP_2010#2153]\n",
      "Keys [1]: [COMM#2540]\n",
      "Functions [1]: [partial_sum(POP_2010#2153)]\n",
      "Aggregate Attributes [1]: [sum#2606L]\n",
      "Results [2]: [COMM#2540, sum#2607L]\n",
      "\n",
      "(48) Exchange\n",
      "Input [2]: [COMM#2540, sum#2607L]\n",
      "Arguments: hashpartitioning(COMM#2540, 1000), ENSURE_REQUIREMENTS, [plan_id=3108]\n",
      "\n",
      "(49) AdaptiveSparkPlan\n",
      "Output [2]: [COMM#2540, sum#2607L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(50) OutputAdapter\n",
      "Output [2]: [COMM#2540, sum#2607L]\n",
      "\n",
      "Subquery:2 Hosting operator id = 7 Hosting Expression = bloomfilter#2602 of [bf2602 COMM#2578 estimatedNumRows=294857] filtering [features#2007.properties.COMM]\n",
      "OutputAdapter (58)\n",
      "+- AdaptiveSparkPlan (57)\n",
      "   +- Exchange (56)\n",
      "      +- Project (55)\n",
      "         +- Filter (54)\n",
      "            +- Generate (53)\n",
      "               +- Filter (52)\n",
      "                  +- Scan geojson  (51)\n",
      "\n",
      "\n",
      "(51) Scan geojson \n",
      "Output [1]: [features#2568]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(52) Filter\n",
      "Input [1]: [features#2568]\n",
      "Condition : ((size(features#2568, true) > 0) AND isnotnull(features#2568))\n",
      "\n",
      "(53) Generate\n",
      "Input [1]: [features#2568]\n",
      "Arguments: explode(features#2568), false, [features#2007]\n",
      "\n",
      "(54) Filter\n",
      "Input [1]: [features#2007]\n",
      "Condition : ((((((isnotnull(features#2007.properties.ZCTA10) AND isnotnull(features#2007.properties.COMM)) AND isnotnull(cast(features#2007.properties.POP_2010 as int))) AND isnotnull(cast(features#2007.properties.HOUSING10 as int))) AND ((cast(features#2007.properties.POP_2010 as int) > 0) AND (cast(features#2007.properties.HOUSING10 as int) > 0))) OR ((cast(features#2007.properties.HOUSING10 as int) = cast(features#2007.properties.POP_2010 as int)) AND (cast(features#2007.properties.HOUSING10 as int) < cast(features#2007.properties.POP_2010 as int)))) AND (isnotnull(features#2007.properties.ZCTA10) AND isnotnull(features#2007.properties.COMM)))\n",
      "\n",
      "(55) Project\n",
      "Output [4]: [features#2007.properties.COMM AS COMM#2578, cast(features#2007.properties.HOUSING10 as int) AS HOUSING10#2180, cast(features#2007.properties.POP_2010 as int) AS POP_2010#2153, features#2007.properties.ZCTA10 AS ZCTA10#2595]\n",
      "Input [1]: [features#2007]\n",
      "\n",
      "(56) Exchange\n",
      "Input [4]: [COMM#2578, HOUSING10#2180, POP_2010#2153, ZCTA10#2595]\n",
      "Arguments: hashpartitioning(cast(ZCTA10#2595 as int), 1000), ENSURE_REQUIREMENTS, [plan_id=3117]\n",
      "\n",
      "(57) AdaptiveSparkPlan\n",
      "Output [4]: [COMM#2578, HOUSING10#2180, POP_2010#2153, ZCTA10#2595]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(58) OutputAdapter\n",
      "Output [4]: [COMM#2578, HOUSING10#2180, POP_2010#2153, ZCTA10#2595]\n",
      "\n",
      "\n",
      "\n",
      "+-----------------------+--------+---------------------+------------------+\n",
      "|COMM                   |POP_2010|crimes_per_person    |income_per_capita |\n",
      "+-----------------------+--------+---------------------+------------------+\n",
      "|Westlake Village       |8152    |1.226692836113837E-4 |44359.271688315865|\n",
      "|Van Nuys               |85959   |0.7382473039472307   |14669.501952996081|\n",
      "|Agoura Hills           |20330   |2.9513034923757994E-4|45007.11862926981 |\n",
      "|Granada Hills          |55172   |0.5292539694047705   |27019.54757800254 |\n",
      "|North Hills            |56344   |0.6136944483884709   |17423.619130778166|\n",
      "|Santa Monica Mountains |17349   |2.3056083924145483E-4|55808.184640564476|\n",
      "|Northridge             |62225   |0.6914262756126959   |24471.89206062434 |\n",
      "|Twin Lakes/Oat Mountain|1446    |0.004149377593360996 |40047.339376789765|\n",
      "|Encino                 |42345   |0.623780847797851    |36441.69325627775 |\n",
      "|Beverly Hills          |33988   |0.026038601859479815 |52096.065991338364|\n",
      "|Beverly Crest          |12191   |0.3689607087195472   |76429.61564264318 |\n",
      "|North Hollywood        |142347  |0.678377486002515    |17174.395854674767|\n",
      "|Canoga Park            |58933   |0.5506083179203503   |17977.40922914295 |\n",
      "|Reseda                 |71818   |0.5522153220641065   |16250.682233725083|\n",
      "|San Fernando           |23639   |0.0038072676509158594|15116.459172732184|\n",
      "|Brentwood              |29298   |0.4058638814936173   |56559.55554024355 |\n",
      "|Mandeville Canyon      |3233    |0.2610578410145376   |62110.61035283743 |\n",
      "|Panorama City          |69500   |0.5084604316546762   |10102.32818052137 |\n",
      "|Lake Balboa            |38811   |0.5426554327381412   |17112.32444075809 |\n",
      "|Winnetka               |47801   |0.5406790652915211   |19486.210870533097|\n",
      "+-----------------------+--------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time with Shuffle Hash joins: 53.758 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from pyspark.sql.functions import col, sum, count, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Δημιουργία Spark και Sedona Context\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeoJSON Read and Process with Suffle_Hash\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "income_csv = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = SedonaContext.create(spark).read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Μορφοποίηση δεδομένων\n",
    "census_2010 = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in\n",
    "     blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Καθαρισμός των δεδομένων του εισοδήματος\n",
    "income_csv = income_csv.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(regexp_replace(col(\"Estimated Median Income\"), \"\\\\$\", \"\"), \",\", \"\").cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Zip Code\",\n",
    "    col(\"Zip Code\").cast(\"int\")\n",
    ")\n",
    "# Μετατροπή της στήλης POP_2010 σε αριθμητικό τύπο\n",
    "census_2010 = census_2010.withColumn(\"POP_2010\", col(\"POP_2010\").cast(\"int\")).withColumn(\"HOUSING10\", col(\"HOUSING10\").cast(\"int\"))\n",
    "\n",
    "# Φιλτράρισμα δεδομένων\n",
    "crime_data = crime_data.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & ((col(\"LAT\") != 0) & (col(\"LON\") != 0)))\n",
    "income_csv = income_csv.filter(col(\"Zip Code\").isNotNull())\n",
    "census_2010 = census_2010.filter((col(\"ZCTA10\").isNotNull()) & (col(\"COMM\").isNotNull()) & (col(\"POP_2010\").isNotNull()) &\n",
    "    (col(\"HOUSING10\").isNotNull()) & ((col(\"POP_2010\") > 0) & (col(\"HOUSING10\") > 0)) |\n",
    "    ((col(\"HOUSING10\") == col(\"POP_2010\")) & (col(\"HOUSING10\") < col(\"POP_2010\")))\n",
    ")\n",
    "\n",
    "start_shuffle = time.time()\n",
    "# Join μεταξύ εισοδήματος και απογραφής\n",
    "census_income_joined = census_2010.join(\n",
    "    income_csv.hint(\"SHUFFLE_HASH\"),\n",
    "    census_2010[\"ZCTA10\"] == income_csv[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικού μέσου εισοδήματος ανα άτομο ανά COMM = sum(housing*income/pop) / φορες εφαρμογής του sum\n",
    "aggregated_income_data = census_income_joined.groupBy(\"COMM\").agg(\n",
    "    (sum((col(\"Estimated Median Income\") * col(\"HOUSING10\") / col(\"POP_2010\")).cast(\"double\")) /\n",
    "     count(\"*\")).alias(\"income_per_capita\")\n",
    ")\n",
    "\n",
    "\n",
    "# Κανονικοποίηση του census_2010 για μοναδικά COMM\n",
    "census_2010_normalized = census_2010.groupBy(\"COMM\").agg(\n",
    "    sum(\"POP_2010\").alias(\"POP_2010\")\n",
    ")\n",
    "\n",
    "# Φόρτωση δεδομένων εγκλημάτων\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"geom\",\n",
    "    ST_Point(\"LON\", \"LAT\")  # Δημιουργία γεωμετρικών σημείων από το LON και LAT\n",
    ")\n",
    "\n",
    "# Σύνδεση crime_data με census_2010 με spatial join\n",
    "joined_df = crime_data.join(\n",
    "    census_2010.hint(\"SHUFFLE_HASH\"),\n",
    "    ST_Within(crime_data[\"geom\"], census_2010[\"geometry\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικών εγκλημάτων ανά COMM\n",
    "crime_by_area = joined_df.groupBy(\"COMM\").agg(\n",
    "    count(\"*\").alias(\"total_crimes\")\n",
    ")\n",
    "\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_with_population = crime_by_area.join(\n",
    "    census_2010_normalized.hint(\"SHUFFLE_HASH\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός εγκλημάτων ανά άτομο\n",
    "crime_with_population = crime_with_population.withColumn(\n",
    "    \"crimes_per_person\",\n",
    "    (col(\"total_crimes\") / col(\"POP_2010\")).cast(\"double\")\n",
    ")\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_income = crime_with_population.join(\n",
    "    aggregated_income_data.hint(\"SHUFFLE_HASH\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "crime_income.explain(mode=\"formatted\")\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "crime_income.select(\"COMM\", \"POP_2010\", \"crimes_per_person\", \"income_per_capita\").show(truncate=False)\n",
    "end_shuffle = time.time()\n",
    "print(f\"Execution time with Shuffle Hash joins: {end_shuffle - start_shuffle:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4f240-bddb-4f67-b334-82f72070ae03",
   "metadata": {},
   "source": [
    "#### SHUFFLE_REPLICATE_NL joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1eeea29-4f9a-4095-b613-91eb5f8a28f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (39)\n",
      "+- Project (38)\n",
      "   +- CartesianProduct Inner (37)\n",
      "      :- Project (23)\n",
      "      :  +- CartesianProduct Inner (22)\n",
      "      :     :- HashAggregate (13)\n",
      "      :     :  +- Exchange (12)\n",
      "      :     :     +- HashAggregate (11)\n",
      "      :     :        +- Project (10)\n",
      "      :     :           +- RangeJoin (9)\n",
      "      :     :              :- Project (3)\n",
      "      :     :              :  +- Filter (2)\n",
      "      :     :              :     +- Scan parquet  (1)\n",
      "      :     :              +- Project (8)\n",
      "      :     :                 +- Filter (7)\n",
      "      :     :                    +- Generate (6)\n",
      "      :     :                       +- Filter (5)\n",
      "      :     :                          +- Scan geojson  (4)\n",
      "      :     +- HashAggregate (21)\n",
      "      :        +- Exchange (20)\n",
      "      :           +- HashAggregate (19)\n",
      "      :              +- Project (18)\n",
      "      :                 +- Filter (17)\n",
      "      :                    +- Generate (16)\n",
      "      :                       +- Filter (15)\n",
      "      :                          +- Scan geojson  (14)\n",
      "      +- HashAggregate (36)\n",
      "         +- Exchange (35)\n",
      "            +- HashAggregate (34)\n",
      "               +- Project (33)\n",
      "                  +- CartesianProduct Inner (32)\n",
      "                     :- Project (28)\n",
      "                     :  +- Filter (27)\n",
      "                     :     +- Generate (26)\n",
      "                     :        +- Filter (25)\n",
      "                     :           +- Scan geojson  (24)\n",
      "                     +- Project (31)\n",
      "                        +- Filter (30)\n",
      "                           +- Scan csv  (29)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [2]: [LAT#2720, LON#2721]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [s3://groups-bucket-dblab-905418150721/group27/Crime_Data]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#2720, LON#2721]\n",
      "Condition : ((((isnotnull(LAT#2720) AND isnotnull(LON#2721)) AND NOT (LAT#2720 = 0.0)) AND NOT (LON#2721 = 0.0)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#3119]\n",
      "Input [2]: [LAT#2720, LON#2721]\n",
      "\n",
      "(4) Scan geojson \n",
      "Output [1]: [features#2788]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(5) Filter\n",
      "Input [1]: [features#2788]\n",
      "Condition : ((size(features#2788, true) > 0) AND isnotnull(features#2788))\n",
      "\n",
      "(6) Generate\n",
      "Input [1]: [features#2788]\n",
      "Arguments: explode(features#2788), false, [features#2796]\n",
      "\n",
      "(7) Filter\n",
      "Input [1]: [features#2796]\n",
      "Condition : ((((((((isnotnull(features#2796.properties.ZCTA10) AND isnotnull(features#2796.properties.COMM)) AND isnotnull(cast(features#2796.properties.POP_2010 as int))) AND isnotnull(cast(features#2796.properties.HOUSING10 as int))) AND ((cast(features#2796.properties.POP_2010 as int) > 0) AND (cast(features#2796.properties.HOUSING10 as int) > 0))) OR ((cast(features#2796.properties.HOUSING10 as int) = cast(features#2796.properties.POP_2010 as int)) AND (cast(features#2796.properties.HOUSING10 as int) < cast(features#2796.properties.POP_2010 as int)))) AND isnotnull(features#2796.geometry)) AND isnotnull(features#2796.properties.COMM)) AND bloomfilter#3392 of [bf3392 COMM#3329 estimatedNumRows=294857] filtering [features#2796.properties.COMM])\n",
      "\n",
      "(8) Project\n",
      "Output [2]: [features#2796.properties.COMM AS COMM#2812, features#2796.geometry AS geometry#2799]\n",
      "Input [1]: [features#2796]\n",
      "\n",
      "(9) RangeJoin\n",
      "Arguments: geom#3119: geometry, geometry#2799: geometry, WITHIN\n",
      "\n",
      "(10) Project\n",
      "Output [1]: [COMM#2812]\n",
      "Input [3]: [geom#3119, COMM#2812, geometry#2799]\n",
      "\n",
      "(11) HashAggregate\n",
      "Input [1]: [COMM#2812]\n",
      "Keys [1]: [COMM#2812]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#3393L]\n",
      "Results [2]: [COMM#2812, count#3394L]\n",
      "\n",
      "(12) Exchange\n",
      "Input [2]: [COMM#2812, count#3394L]\n",
      "Arguments: hashpartitioning(COMM#2812, 1000), ENSURE_REQUIREMENTS, [plan_id=4524]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [2]: [COMM#2812, count#3394L]\n",
      "Keys [1]: [COMM#2812]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#3314L]\n",
      "Results [2]: [COMM#2812, count(1)#3314L AS total_crimes#3315L]\n",
      "\n",
      "(14) Scan geojson \n",
      "Output [1]: [features#3319]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(15) Filter\n",
      "Input [1]: [features#3319]\n",
      "Condition : ((size(features#3319, true) > 0) AND isnotnull(features#3319))\n",
      "\n",
      "(16) Generate\n",
      "Input [1]: [features#3319]\n",
      "Arguments: explode(features#3319), false, [features#2796]\n",
      "\n",
      "(17) Filter\n",
      "Input [1]: [features#2796]\n",
      "Condition : ((((((isnotnull(features#2796.properties.ZCTA10) AND isnotnull(features#2796.properties.COMM)) AND isnotnull(cast(features#2796.properties.POP_2010 as int))) AND isnotnull(cast(features#2796.properties.HOUSING10 as int))) AND ((cast(features#2796.properties.POP_2010 as int) > 0) AND (cast(features#2796.properties.HOUSING10 as int) > 0))) OR ((cast(features#2796.properties.HOUSING10 as int) = cast(features#2796.properties.POP_2010 as int)) AND (cast(features#2796.properties.HOUSING10 as int) < cast(features#2796.properties.POP_2010 as int)))) AND isnotnull(features#2796.properties.COMM))\n",
      "\n",
      "(18) Project\n",
      "Output [2]: [features#2796.properties.COMM AS COMM#3329, cast(features#2796.properties.POP_2010 as int) AS POP_2010#2942]\n",
      "Input [1]: [features#2796]\n",
      "\n",
      "(19) HashAggregate\n",
      "Input [2]: [COMM#3329, POP_2010#2942]\n",
      "Keys [1]: [COMM#3329]\n",
      "Functions [1]: [partial_sum(POP_2010#2942)]\n",
      "Aggregate Attributes [1]: [sum#3395L]\n",
      "Results [2]: [COMM#3329, sum#3396L]\n",
      "\n",
      "(20) Exchange\n",
      "Input [2]: [COMM#3329, sum#3396L]\n",
      "Arguments: hashpartitioning(COMM#3329, 1000), ENSURE_REQUIREMENTS, [plan_id=4423]\n",
      "\n",
      "(21) HashAggregate\n",
      "Input [2]: [COMM#3329, sum#3396L]\n",
      "Keys [1]: [COMM#3329]\n",
      "Functions [1]: [sum(POP_2010#2942)]\n",
      "Aggregate Attributes [1]: [sum(POP_2010#2942)#3115L]\n",
      "Results [2]: [COMM#3329, sum(POP_2010#2942)#3115L AS POP_2010#3116L]\n",
      "\n",
      "(22) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (COMM#2812 = COMM#3329)\n",
      "\n",
      "(23) Project\n",
      "Output [4]: [COMM#2812, total_crimes#3315L, POP_2010#3116L, (cast(total_crimes#3315L as double) / cast(POP_2010#3116L as double)) AS crimes_per_person#3351]\n",
      "Input [4]: [COMM#2812, total_crimes#3315L, COMM#3329, POP_2010#3116L]\n",
      "\n",
      "(24) Scan geojson \n",
      "Output [1]: [features#3357]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(25) Filter\n",
      "Input [1]: [features#3357]\n",
      "Condition : ((size(features#3357, true) > 0) AND isnotnull(features#3357))\n",
      "\n",
      "(26) Generate\n",
      "Input [1]: [features#3357]\n",
      "Arguments: explode(features#3357), false, [features#2796]\n",
      "\n",
      "(27) Filter\n",
      "Input [1]: [features#2796]\n",
      "Condition : ((((((isnotnull(features#2796.properties.ZCTA10) AND isnotnull(features#2796.properties.COMM)) AND isnotnull(cast(features#2796.properties.POP_2010 as int))) AND isnotnull(cast(features#2796.properties.HOUSING10 as int))) AND ((cast(features#2796.properties.POP_2010 as int) > 0) AND (cast(features#2796.properties.HOUSING10 as int) > 0))) OR ((cast(features#2796.properties.HOUSING10 as int) = cast(features#2796.properties.POP_2010 as int)) AND (cast(features#2796.properties.HOUSING10 as int) < cast(features#2796.properties.POP_2010 as int)))) AND (isnotnull(features#2796.properties.ZCTA10) AND isnotnull(features#2796.properties.COMM)))\n",
      "\n",
      "(28) Project\n",
      "Output [4]: [features#2796.properties.COMM AS COMM#3367, cast(features#2796.properties.HOUSING10 as int) AS HOUSING10#2969, cast(features#2796.properties.POP_2010 as int) AS POP_2010#2942, features#2796.properties.ZCTA10 AS ZCTA10#3384]\n",
      "Input [1]: [features#2796]\n",
      "\n",
      "(29) Scan csv \n",
      "Output [2]: [Zip Code#2768, Estimated Median Income#2770]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(30) Filter\n",
      "Input [2]: [Zip Code#2768, Estimated Median Income#2770]\n",
      "Condition : isnotnull(Zip Code#2768)\n",
      "\n",
      "(31) Project\n",
      "Output [2]: [Zip Code#2768, cast(regexp_replace(regexp_replace(Estimated Median Income#2770, \\$, , 1), ,, , 1) as int) AS Estimated Median Income#2933]\n",
      "Input [2]: [Zip Code#2768, Estimated Median Income#2770]\n",
      "\n",
      "(32) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (cast(ZCTA10#3384 as int) = Zip Code#2768)\n",
      "\n",
      "(33) Project\n",
      "Output [4]: [COMM#3367, HOUSING10#2969, POP_2010#2942, Estimated Median Income#2933]\n",
      "Input [6]: [COMM#3367, HOUSING10#2969, POP_2010#2942, ZCTA10#3384, Zip Code#2768, Estimated Median Income#2933]\n",
      "\n",
      "(34) HashAggregate\n",
      "Input [4]: [COMM#3367, HOUSING10#2969, POP_2010#2942, Estimated Median Income#2933]\n",
      "Keys [1]: [COMM#3367]\n",
      "Functions [2]: [partial_sum((cast((Estimated Median Income#2933 * HOUSING10#2969) as double) / cast(POP_2010#2942 as double))), partial_count(1)]\n",
      "Aggregate Attributes [2]: [sum#3397, count#3399L]\n",
      "Results [3]: [COMM#3367, sum#3398, count#3400L]\n",
      "\n",
      "(35) Exchange\n",
      "Input [3]: [COMM#3367, sum#3398, count#3400L]\n",
      "Arguments: hashpartitioning(COMM#3367, 1000), ENSURE_REQUIREMENTS, [plan_id=4427]\n",
      "\n",
      "(36) HashAggregate\n",
      "Input [3]: [COMM#3367, sum#3398, count#3400L]\n",
      "Keys [1]: [COMM#3367]\n",
      "Functions [2]: [sum((cast((Estimated Median Income#2933 * HOUSING10#2969) as double) / cast(POP_2010#2942 as double))), count(1)]\n",
      "Aggregate Attributes [2]: [sum((cast((Estimated Median Income#2933 * HOUSING10#2969) as double) / cast(POP_2010#2942 as double)))#3084, count(1)#3085L]\n",
      "Results [2]: [COMM#3367, (sum((cast((Estimated Median Income#2933 * HOUSING10#2969) as double) / cast(POP_2010#2942 as double)))#3084 / cast(count(1)#3085L as double)) AS income_per_capita#3086]\n",
      "\n",
      "(37) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (COMM#2812 = COMM#3367)\n",
      "\n",
      "(38) Project\n",
      "Output [5]: [COMM#2812, total_crimes#3315L, POP_2010#3116L, crimes_per_person#3351, income_per_capita#3086]\n",
      "Input [6]: [COMM#2812, total_crimes#3315L, POP_2010#3116L, crimes_per_person#3351, COMM#3367, income_per_capita#3086]\n",
      "\n",
      "(39) AdaptiveSparkPlan\n",
      "Output [5]: [COMM#2812, total_crimes#3315L, POP_2010#3116L, crimes_per_person#3351, income_per_capita#3086]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "===== Subqueries =====\n",
      "\n",
      "Subquery:1 Hosting operator id = 7 Hosting Expression = bloomfilter#3392 of [bf3392 COMM#3329 estimatedNumRows=294857] filtering [features#2796.properties.COMM]\n",
      "OutputAdapter (48)\n",
      "+- AdaptiveSparkPlan (47)\n",
      "   +- Exchange (46)\n",
      "      +- HashAggregate (45)\n",
      "         +- Project (44)\n",
      "            +- Filter (43)\n",
      "               +- Generate (42)\n",
      "                  +- Filter (41)\n",
      "                     +- Scan geojson  (40)\n",
      "\n",
      "\n",
      "(40) Scan geojson \n",
      "Output [1]: [features#3319]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(41) Filter\n",
      "Input [1]: [features#3319]\n",
      "Condition : ((size(features#3319, true) > 0) AND isnotnull(features#3319))\n",
      "\n",
      "(42) Generate\n",
      "Input [1]: [features#3319]\n",
      "Arguments: explode(features#3319), false, [features#2796]\n",
      "\n",
      "(43) Filter\n",
      "Input [1]: [features#2796]\n",
      "Condition : ((((((isnotnull(features#2796.properties.ZCTA10) AND isnotnull(features#2796.properties.COMM)) AND isnotnull(cast(features#2796.properties.POP_2010 as int))) AND isnotnull(cast(features#2796.properties.HOUSING10 as int))) AND ((cast(features#2796.properties.POP_2010 as int) > 0) AND (cast(features#2796.properties.HOUSING10 as int) > 0))) OR ((cast(features#2796.properties.HOUSING10 as int) = cast(features#2796.properties.POP_2010 as int)) AND (cast(features#2796.properties.HOUSING10 as int) < cast(features#2796.properties.POP_2010 as int)))) AND isnotnull(features#2796.properties.COMM))\n",
      "\n",
      "(44) Project\n",
      "Output [2]: [features#2796.properties.COMM AS COMM#3329, cast(features#2796.properties.POP_2010 as int) AS POP_2010#2942]\n",
      "Input [1]: [features#2796]\n",
      "\n",
      "(45) HashAggregate\n",
      "Input [2]: [COMM#3329, POP_2010#2942]\n",
      "Keys [1]: [COMM#3329]\n",
      "Functions [1]: [partial_sum(POP_2010#2942)]\n",
      "Aggregate Attributes [1]: [sum#3395L]\n",
      "Results [2]: [COMM#3329, sum#3396L]\n",
      "\n",
      "(46) Exchange\n",
      "Input [2]: [COMM#3329, sum#3396L]\n",
      "Arguments: hashpartitioning(COMM#3329, 1000), ENSURE_REQUIREMENTS, [plan_id=4514]\n",
      "\n",
      "(47) AdaptiveSparkPlan\n",
      "Output [2]: [COMM#3329, sum#3396L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(48) OutputAdapter\n",
      "Output [2]: [COMM#3329, sum#3396L]\n",
      "\n",
      "\n",
      "\n",
      "+---------------------+--------+---------------------+------------------+\n",
      "|COMM                 |POP_2010|crimes_per_person    |income_per_capita |\n",
      "+---------------------+--------+---------------------+------------------+\n",
      "|Rosewood/East Gardena|1164    |0.08676975945017182  |20167.937355132806|\n",
      "|Green Meadows        |19814   |1.020995255879681    |8413.214132045203 |\n",
      "|Carson               |91094   |0.002437043054427295 |22977.091884112353|\n",
      "|Rowland Heights      |48982   |4.0831325793148504E-5|19375.50202135718 |\n",
      "|Signal Hill          |11014   |9.079353550027238E-5 |27256.91151709997 |\n",
      "|Gardena              |58818   |0.0054915162025230375|17976.0978751902  |\n",
      "|Norwalk              |104815  |9.540619186185184E-6 |16294.194056832279|\n",
      "|Maywood              |27395   |3.650301149844862E-5 |8899.55096867617  |\n",
      "|Paramount            |54089   |5.5464142431917764E-5|12964.10762392401 |\n",
      "|Commerce             |12822   |2.339728591483388E-4 |13306.75660538827 |\n",
      "|Century Palms/Cove   |30481   |1.1446474853187232   |8967.550330437702 |\n",
      "|Figueroa Park Square |8272    |0.9028046421663443   |9432.150264604014 |\n",
      "|Harbor City          |26767   |0.4932192625247506   |30207.450134917046|\n",
      "|La Mirada            |46414   |2.1545223423966907E-5|26630.256496508704|\n",
      "|South Park           |35235   |0.8028097062579821   |7463.056702664662 |\n",
      "|Diamond Bar          |55542   |1.8004393071909547E-5|30733.508082599186|\n",
      "|West Vernon          |50300   |1.0376739562624255   |9246.968909431453 |\n",
      "|Vernon Central       |48768   |0.6563935367454068   |6630.487311239118 |\n",
      "|Walnut Park          |15966   |1.252661906551422E-4 |8668.58061105109  |\n",
      "|Compton              |96358   |4.151186201457066E-5 |11765.255922706285|\n",
      "+---------------------+--------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time with SHUFFLE_REPLICATE_NL joins: 37.149 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from pyspark.sql.functions import col, sum, count, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Δημιουργία Spark και Sedona Context\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeoJSON Read and Process with Suffle_Replicate_nl\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "income_csv = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = SedonaContext.create(spark).read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Μορφοποίηση δεδομένων\n",
    "census_2010 = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in\n",
    "     blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Καθαρισμός των δεδομένων του εισοδήματος\n",
    "income_csv = income_csv.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(regexp_replace(col(\"Estimated Median Income\"), \"\\\\$\", \"\"), \",\", \"\").cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Zip Code\",\n",
    "    col(\"Zip Code\").cast(\"int\")\n",
    ")\n",
    "# Μετατροπή της στήλης POP_2010 σε αριθμητικό τύπο\n",
    "census_2010 = census_2010.withColumn(\"POP_2010\", col(\"POP_2010\").cast(\"int\")).withColumn(\"HOUSING10\", col(\"HOUSING10\").cast(\"int\"))\n",
    "\n",
    "# Φιλτράρισμα δεδομένων\n",
    "crime_data = crime_data.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & ((col(\"LAT\") != 0) & (col(\"LON\") != 0)))\n",
    "income_csv = income_csv.filter(col(\"Zip Code\").isNotNull())\n",
    "census_2010 = census_2010.filter((col(\"ZCTA10\").isNotNull()) & (col(\"COMM\").isNotNull()) & (col(\"POP_2010\").isNotNull()) &\n",
    "    (col(\"HOUSING10\").isNotNull()) & ((col(\"POP_2010\") > 0) & (col(\"HOUSING10\") > 0)) |\n",
    "    ((col(\"HOUSING10\") == col(\"POP_2010\")) & (col(\"HOUSING10\") < col(\"POP_2010\")))\n",
    ")\n",
    "\n",
    "start_rep = time.time()\n",
    "# Join μεταξύ εισοδήματος και απογραφής\n",
    "census_income_joined = census_2010.join(\n",
    "    income_csv.hint(\"SHUFFLE_REPLICATE_NL\"),\n",
    "    census_2010[\"ZCTA10\"] == income_csv[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικού μέσου εισοδήματος ανα άτομο ανά COMM = sum(housing*income/pop) / φορες εφαρμογής του sum\n",
    "aggregated_income_data = census_income_joined.groupBy(\"COMM\").agg(\n",
    "    (sum((col(\"Estimated Median Income\") * col(\"HOUSING10\") / col(\"POP_2010\")).cast(\"double\")) /\n",
    "     count(\"*\")).alias(\"income_per_capita\")\n",
    ")\n",
    "\n",
    "\n",
    "# Κανονικοποίηση του census_2010 για μοναδικά COMM\n",
    "census_2010_normalized = census_2010.groupBy(\"COMM\").agg(\n",
    "    sum(\"POP_2010\").alias(\"POP_2010\")\n",
    ")\n",
    "\n",
    "# Φόρτωση δεδομένων εγκλημάτων\n",
    "crime_data = crime_data.withColumn(\n",
    "    \"geom\",\n",
    "    ST_Point(\"LON\", \"LAT\")  # Δημιουργία γεωμετρικών σημείων από το LON και LAT\n",
    ")\n",
    "\n",
    "# Σύνδεση crime_data με census_2010 με spatial join\n",
    "joined_df = crime_data.join(\n",
    "    census_2010.hint(\"SHUFFLE_REPLICATE_NL\"),\n",
    "    ST_Within(crime_data[\"geom\"], census_2010[\"geometry\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικών εγκλημάτων ανά COMM\n",
    "crime_by_area = joined_df.groupBy(\"COMM\").agg(\n",
    "    count(\"*\").alias(\"total_crimes\")\n",
    ")\n",
    "\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_with_population = crime_by_area.join(\n",
    "    census_2010_normalized.hint(\"SHUFFLE_REPLICATE_NL\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός εγκλημάτων ανά άτομο\n",
    "crime_with_population = crime_with_population.withColumn(\n",
    "    \"crimes_per_person\",\n",
    "    (col(\"total_crimes\") / col(\"POP_2010\")).cast(\"double\")\n",
    ")\n",
    "# Συνένωση με πληθυσμό\n",
    "crime_income = crime_with_population.join(\n",
    "    aggregated_income_data.hint(\"SHUFFLE_REPLICATE_NL\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "crime_income.explain(mode=\"formatted\")\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "crime_income.select(\"COMM\", \"POP_2010\", \"crimes_per_person\", \"income_per_capita\").show(truncate=False)\n",
    "end_rep = time.time()\n",
    "print(f\"Execution time with SHUFFLE_REPLICATE_NL joins: {end_rep - start_rep:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68321380-291c-4f6f-acf9-a354310180e4",
   "metadata": {},
   "source": [
    "# Query 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e417b-77ff-4d21-b45a-a1b3b3bfe480",
   "metadata": {},
   "source": [
    "### 2 Executors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc8c5b-8601-47db-856a-afebefe84901",
   "metadata": {},
   "source": [
    "#### 1core/2 GB memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c43e5f-ddfc-4215-b9b6-3be7d4bc34fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for 3 regions with the highest per capita income\n",
      "+----------------------+-------------+\n",
      "|Victim Descent        |Victim Number|\n",
      "+----------------------+-------------+\n",
      "|White                 |252          |\n",
      "|Other                 |77           |\n",
      "|Hispanic/Latin/Mexican|23           |\n",
      "|Black                 |13           |\n",
      "|Other Asian           |12           |\n",
      "|Unknown               |8            |\n",
      "+----------------------+-------------+\n",
      "\n",
      "Table for 3 regions with the lowest per capita income\n",
      "+------------------------------+-------------+\n",
      "|Victim Descent                |Victim Number|\n",
      "+------------------------------+-------------+\n",
      "|Hispanic/Latin/Mexican        |2413         |\n",
      "|Black                         |638          |\n",
      "|Other                         |111          |\n",
      "|White                         |53           |\n",
      "|Other Asian                   |6            |\n",
      "|Unknown                       |3            |\n",
      "|Filipino                      |1            |\n",
      "|Korean                        |1            |\n",
      "|American Indian/Alaskan Native|1            |\n",
      "+------------------------------+-------------+\n",
      "\n",
      "Execution time with 1core/2 GB memory: 51.539 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from pyspark.sql.functions import col, sum, count, regexp_replace, desc\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Ρύθμιση Spark Session για 1 core και 2 GB memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"1core/2 GB memory\") \\\n",
    "    .config(\"spark.executor.instances\", 2) \\\n",
    "    .config(\"spark.executor.cores\", 1) \\\n",
    "    .config(\"spark.executor.memory\", \"2G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "income_csv = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = SedonaContext.create(spark).read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Μορφοποίηση δεδομένων\n",
    "census_2010 = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in\n",
    "     blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Καθαρισμός των δεδομένων του εισοδήματος\n",
    "income_csv = income_csv.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(regexp_replace(col(\"Estimated Median Income\"), \"\\\\$\", \"\"), \",\", \"\").cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Zip Code\",\n",
    "    col(\"Zip Code\").cast(\"int\")\n",
    ")\n",
    "\n",
    "# Μετατροπή των στηλών που φιλτράρουμε σε αριθμητικό τύπο int.\n",
    "census_2010 = census_2010.withColumn(\"POP_2010\", col(\"POP_2010\").cast(\"int\")).withColumn(\"HOUSING10\", col(\"HOUSING10\").cast(\"int\"))\n",
    "\n",
    "# Φιλτράρισμα δεδομένων\n",
    "crime_data = crime_data.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & ((col(\"LAT\") != 0) & (col(\"LON\") != 0)))\n",
    "income_csv = income_csv.filter(col(\"Zip Code\").isNotNull())\n",
    "census_2010 = census_2010.filter((col(\"ZCTA10\").isNotNull()) & (col(\"COMM\").isNotNull()) & (col(\"POP_2010\").isNotNull()) &\n",
    "    (col(\"HOUSING10\").isNotNull()) & ((col(\"POP_2010\") > 0) & (col(\"HOUSING10\") > 0)) |\n",
    "    ((col(\"HOUSING10\") == col(\"POP_2010\")) & (col(\"HOUSING10\") < col(\"POP_2010\")))\n",
    ")\n",
    "\n",
    "start_rep = time.time()\n",
    "\n",
    "# Join μεταξύ εισοδήματος και απογραφής\n",
    "census_income_joined = census_2010.join(\n",
    "    income_csv,\n",
    "    census_2010[\"ZCTA10\"] == income_csv[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικού εισοδήματος ανά COMM = sum(housing*income/pop) / φορες εφαρμογής του sum\n",
    "aggregated_income_data = census_income_joined.groupBy(\"COMM\").agg(\n",
    "    (sum((col(\"Estimated Median Income\") * col(\"HOUSING10\") / col(\"POP_2010\")).cast(\"double\")) /\n",
    "     count(\"*\")).alias(\"income_per_capita\")\n",
    ")\n",
    "\n",
    "\n",
    "# Φόρτωση δεδομένων εγκλημάτων\n",
    "crime_data_2015 = crime_data.filter(col(\"DATE OCC\").contains(\"2015\")) # Κραταμε μονο του 2015 crime_data\n",
    "crime_data = crime_data_2015.withColumn(\n",
    "    \"geom\",\n",
    "    ST_Point(\"LON\", \"LAT\")  # Δημιουργία γεωμετρικών σημείων από το LON και LAT\n",
    ")\n",
    "\n",
    "# Σύνδεση crime_data με census_2010 με spatial join\n",
    "joined_df = crime_data.join(\n",
    "    census_2010,\n",
    "    ST_Within(crime_data[\"geom\"], census_2010[\"geometry\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Προσθήκη εισοδήματος\n",
    "crime_with_income = joined_df.join(\n",
    "    aggregated_income_data,\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Εύρεση των 3 περιοχών με υψηλότερο και χαμηλότερο εισόδημα\n",
    "top_income_areas = aggregated_income_data.orderBy(col(\"income_per_capita\").desc()).limit(3)\n",
    "low_income_areas = aggregated_income_data.orderBy(col(\"income_per_capita\").asc()).limit(3)\n",
    "\n",
    "# Φιλτράρισμα εγκλημάτων για τις περιοχές αυτές\n",
    "crime_top_income = crime_with_income.join(top_income_areas, \"COMM\", \"inner\")\n",
    "crime_low_income = crime_with_income.join(low_income_areas, \"COMM\", \"inner\")\n",
    "\n",
    "# Φόρτωση του RE (Race and Ethnicity codes)\n",
    "re_codes = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/RE_codes.csv\", header=False, inferSchema=True)\n",
    "re_codes = re_codes.withColumnRenamed(\"_c1\", \"Victim Descent\")\n",
    "\n",
    "# Αντιστοίχιση φυλετικής καταγωγής\n",
    "crime_top_income = crime_top_income.join(re_codes, crime_top_income[\"Vict Descent\"] == re_codes[\"_c0\"], \"inner\")\n",
    "crime_low_income = crime_low_income.join(re_codes, crime_low_income[\"Vict Descent\"] == re_codes[\"_c0\"], \"inner\")\n",
    "\n",
    "\n",
    "# Ομαδοποίηση ανά Victim Descent, μέτρηση, αύξουσα ταξινόμηση\n",
    "crime_top_income = crime_top_income.groupBy(\"Victim Descent\").agg(count(\"*\").alias(\"Victim Number\")).orderBy(col(\"Victim Number\").desc())\n",
    "print(\"Table for 3 regions with the highest per capita income\")\n",
    "crime_top_income.show(truncate=False)\n",
    "\n",
    "print(\"Table for 3 regions with the lowest per capita income\")\n",
    "crime_low_income = crime_low_income.groupBy(\"Victim Descent\").agg(count(\"*\").alias(\"Victim Number\")).orderBy(col(\"Victim Number\").desc())\n",
    "crime_low_income.show(truncate=False)\n",
    "\n",
    "end_rep = time.time()\n",
    "print(f\"Execution time with 1core/2 GB memory: {end_rep - start_rep:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011361b2-98c0-4fb2-9a16-bf30e29a3a1b",
   "metadata": {},
   "source": [
    "#### 2cores/4GB memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee073ff4-af36-41ad-839f-497b8602b87d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for 3 regions with the highest per capita income\n",
      "+----------------------+-------------+\n",
      "|Victim Descent        |Victim Number|\n",
      "+----------------------+-------------+\n",
      "|White                 |252          |\n",
      "|Other                 |77           |\n",
      "|Hispanic/Latin/Mexican|23           |\n",
      "|Black                 |13           |\n",
      "|Other Asian           |12           |\n",
      "|Unknown               |8            |\n",
      "+----------------------+-------------+\n",
      "\n",
      "Table for 3 regions with the lowest per capita income\n",
      "+------------------------------+-------------+\n",
      "|Victim Descent                |Victim Number|\n",
      "+------------------------------+-------------+\n",
      "|Hispanic/Latin/Mexican        |2413         |\n",
      "|Black                         |638          |\n",
      "|Other                         |111          |\n",
      "|White                         |53           |\n",
      "|Other Asian                   |6            |\n",
      "|Unknown                       |3            |\n",
      "|Korean                        |1            |\n",
      "|American Indian/Alaskan Native|1            |\n",
      "|Filipino                      |1            |\n",
      "+------------------------------+-------------+\n",
      "\n",
      "Execution time with 2cores/4GB memory: 60.652 seconds"
     ]
    }
   ],
   "source": [
    "# Ρύθμιση Spark Session για 1 core και 2 GB memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"2cores/4GB memory\") \\\n",
    "    .config(\"spark.executor.instances\", 2) \\\n",
    "    .config(\"spark.executor.cores\", 2) \\\n",
    "    .config(\"spark.executor.memory\", \"4G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "income_csv = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = SedonaContext.create(spark).read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Μορφοποίηση δεδομένων\n",
    "census_2010 = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in\n",
    "     blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Καθαρισμός των δεδομένων του εισοδήματος\n",
    "income_csv = income_csv.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(regexp_replace(col(\"Estimated Median Income\"), \"\\\\$\", \"\"), \",\", \"\").cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Zip Code\",\n",
    "    col(\"Zip Code\").cast(\"int\")\n",
    ")\n",
    "# Μετατροπή των στηλών που φιλτράρουμε μετά σε αριθμητικό τύπο int.\n",
    "census_2010 = census_2010.withColumn(\"POP_2010\", col(\"POP_2010\").cast(\"int\")).withColumn(\"HOUSING10\", col(\"HOUSING10\").cast(\"int\"))\n",
    "\n",
    "# Φιλτράρισμα δεδομένων\n",
    "crime_data = crime_data.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & ((col(\"LAT\") != 0) & (col(\"LON\") != 0)))\n",
    "income_csv = income_csv.filter(col(\"Zip Code\").isNotNull())\n",
    "census_2010 = census_2010.filter((col(\"ZCTA10\").isNotNull()) & (col(\"COMM\").isNotNull()) & (col(\"POP_2010\").isNotNull()) &\n",
    "    (col(\"HOUSING10\").isNotNull()) & ((col(\"POP_2010\") > 0) & (col(\"HOUSING10\") > 0)) |\n",
    "    ((col(\"HOUSING10\") == col(\"POP_2010\")) & (col(\"HOUSING10\") < col(\"POP_2010\")))\n",
    ")\n",
    "\n",
    "start_rep = time.time()\n",
    "\n",
    "# Join μεταξύ εισοδήματος και απογραφής\n",
    "census_income_joined = census_2010.join(\n",
    "    income_csv,\n",
    "    census_2010[\"ZCTA10\"] == income_csv[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικού εισοδήματος ανά COMM = sum(housing*income/pop) / φορες εφαρμογής του sum\n",
    "aggregated_income_data = census_income_joined.groupBy(\"COMM\").agg(\n",
    "    (sum((col(\"Estimated Median Income\") * col(\"HOUSING10\") / col(\"POP_2010\")).cast(\"double\")) /\n",
    "     count(\"*\")).alias(\"income_per_capita\")\n",
    ")\n",
    "\n",
    "\n",
    "# Φόρτωση δεδομένων εγκλημάτων\n",
    "crime_data_2015 = crime_data.filter(col(\"DATE OCC\").contains(\"2015\")) # Κραταμε μονο του 2015 crime_data\n",
    "crime_data = crime_data_2015.withColumn(\n",
    "    \"geom\",\n",
    "    ST_Point(\"LON\", \"LAT\")  # Δημιουργία γεωμετρικών σημείων από το LON και LAT\n",
    ")\n",
    "\n",
    "# Σύνδεση crime_data με census_2010 με spatial join\n",
    "joined_df = crime_data.join(\n",
    "    census_2010,\n",
    "    ST_Within(crime_data[\"geom\"], census_2010[\"geometry\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Προσθήκη εισοδήματος\n",
    "crime_with_income = joined_df.join(\n",
    "    aggregated_income_data,\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Εύρεση των 3 περιοχών με υψηλότερο και χαμηλότερο εισόδημα\n",
    "top_income_areas = aggregated_income_data.orderBy(col(\"income_per_capita\").desc()).limit(3)\n",
    "low_income_areas = aggregated_income_data.orderBy(col(\"income_per_capita\").asc()).limit(3)\n",
    "\n",
    "# Φιλτράρισμα εγκλημάτων για τις περιοχές αυτές\n",
    "crime_top_income = crime_with_income.join(top_income_areas, \"COMM\", \"inner\")\n",
    "crime_low_income = crime_with_income.join(low_income_areas, \"COMM\", \"inner\")\n",
    "\n",
    "# Φόρτωση του RE (Race and Ethnicity codes)\n",
    "re_codes = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/RE_codes.csv\", header=False, inferSchema=True)\n",
    "re_codes = re_codes.withColumnRenamed(\"_c1\", \"Victim Descent\")\n",
    "\n",
    "# Αντιστοίχιση φυλετικής καταγωγής\n",
    "crime_top_income = crime_top_income.join(re_codes, crime_top_income[\"Vict Descent\"] == re_codes[\"_c0\"], \"inner\")\n",
    "crime_low_income = crime_low_income.join(re_codes, crime_low_income[\"Vict Descent\"] == re_codes[\"_c0\"], \"inner\")\n",
    "\n",
    "# Ομαδοποίηση ανά Victim Descent, μέτρηση, αύξουσα ταξινόμηση\n",
    "crime_top_income = crime_top_income.groupBy(\"Victim Descent\").agg(count(\"*\").alias(\"Victim Number\")).orderBy(col(\"Victim Number\").desc())\n",
    "print(\"Table for 3 regions with the highest per capita income\")\n",
    "crime_top_income.show(truncate=False)\n",
    "\n",
    "print(\"Table for 3 regions with the lowest per capita income\")\n",
    "crime_low_income = crime_low_income.groupBy(\"Victim Descent\").agg(count(\"*\").alias(\"Victim Number\")).orderBy(col(\"Victim Number\").desc())\n",
    "crime_low_income.show(truncate=False)\n",
    "\n",
    "end_rep = time.time()\n",
    "print(f\"Execution time with 2cores/4GB memory: {end_rep - start_rep:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2b9e3-0d4a-4178-b667-08d6f5da032a",
   "metadata": {},
   "source": [
    "#### 4cores/8GB memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73218f06-15c2-4e9c-ac27-9e227629169c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for 3 regions with the highest per capita income\n",
      "+----------------------+-------------+\n",
      "|Victim Descent        |Victim Number|\n",
      "+----------------------+-------------+\n",
      "|White                 |252          |\n",
      "|Other                 |77           |\n",
      "|Hispanic/Latin/Mexican|23           |\n",
      "|Black                 |13           |\n",
      "|Other Asian           |12           |\n",
      "|Unknown               |8            |\n",
      "+----------------------+-------------+\n",
      "\n",
      "Table for 3 regions with the lowest per capita income\n",
      "+------------------------------+-------------+\n",
      "|Victim Descent                |Victim Number|\n",
      "+------------------------------+-------------+\n",
      "|Hispanic/Latin/Mexican        |2413         |\n",
      "|Black                         |638          |\n",
      "|Other                         |111          |\n",
      "|White                         |53           |\n",
      "|Other Asian                   |6            |\n",
      "|Unknown                       |3            |\n",
      "|Filipino                      |1            |\n",
      "|Korean                        |1            |\n",
      "|American Indian/Alaskan Native|1            |\n",
      "+------------------------------+-------------+\n",
      "\n",
      "Execution time with 4cores/8GB memory: 65.042 seconds"
     ]
    }
   ],
   "source": [
    "# Ρύθμιση Spark Session για 1 core και 2 GB memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"4cores/8GB memory\") \\\n",
    "    .config(\"spark.executor.instances\", 2) \\\n",
    "    .config(\"spark.executor.cores\", 4) \\\n",
    "    .config(\"spark.executor.memory\", \"8G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "income_csv = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = SedonaContext.create(spark).read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Μορφοποίηση δεδομένων\n",
    "census_2010 = blocks_df.select(\n",
    "    [col(f\"properties.{col_name}\").alias(col_name) for col_name in\n",
    "     blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]\n",
    ").drop(\"properties\").drop(\"type\")\n",
    "\n",
    "# Καθαρισμός των δεδομένων του εισοδήματος\n",
    "income_csv = income_csv.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(regexp_replace(col(\"Estimated Median Income\"), \"\\\\$\", \"\"), \",\", \"\").cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Zip Code\",\n",
    "    col(\"Zip Code\").cast(\"int\")\n",
    ")\n",
    "# Μετατροπή των στηλών που φιλτράρουμε σε αριθμητικό τύπο int.\n",
    "census_2010 = census_2010.withColumn(\"POP_2010\", col(\"POP_2010\").cast(\"int\")).withColumn(\"HOUSING10\", col(\"HOUSING10\").cast(\"int\"))\n",
    "\n",
    "# Φιλτράρισμα δεδομένων\n",
    "crime_data = crime_data.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & ((col(\"LAT\") != 0) & (col(\"LON\") != 0)))\n",
    "income_csv = income_csv.filter(col(\"Zip Code\").isNotNull())\n",
    "census_2010 = census_2010.filter((col(\"ZCTA10\").isNotNull()) & (col(\"COMM\").isNotNull()) & (col(\"POP_2010\").isNotNull()) &\n",
    "    (col(\"HOUSING10\").isNotNull()) & ((col(\"POP_2010\") > 0) & (col(\"HOUSING10\") > 0)) |\n",
    "    ((col(\"HOUSING10\") == col(\"POP_2010\")) & (col(\"HOUSING10\") < col(\"POP_2010\")))\n",
    ")\n",
    "\n",
    "start_rep = time.time()\n",
    "\n",
    "# Join μεταξύ εισοδήματος και απογραφής\n",
    "census_income_joined = census_2010.join(\n",
    "    income_csv,\n",
    "    census_2010[\"ZCTA10\"] == income_csv[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός συνολικού εισοδήματος ανά COMM = sum(housing*income/pop) / φορες εφαρμογής του sum\n",
    "aggregated_income_data = census_income_joined.groupBy(\"COMM\").agg(\n",
    "    (sum((col(\"Estimated Median Income\") * col(\"HOUSING10\") / col(\"POP_2010\")).cast(\"double\")) /\n",
    "     count(\"*\")).alias(\"income_per_capita\")\n",
    ")\n",
    "\n",
    "\n",
    "# Φόρτωση δεδομένων εγκλημάτων\n",
    "crime_data_2015 = crime_data.filter(col(\"DATE OCC\").contains(\"2015\")) # Κραταμε μονο του 2015 crime_data\n",
    "crime_data = crime_data_2015.withColumn(\n",
    "    \"geom\",\n",
    "    ST_Point(\"LON\", \"LAT\")  # Δημιουργία γεωμετρικών σημείων από το LON και LAT\n",
    ")\n",
    "\n",
    "# Σύνδεση crime_data με census_2010 με spatial join\n",
    "joined_df = crime_data.join(\n",
    "    census_2010,\n",
    "    ST_Within(crime_data[\"geom\"], census_2010[\"geometry\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Προσθήκη εισοδήματος\n",
    "crime_with_income = joined_df.join(\n",
    "    aggregated_income_data,\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Εύρεση των 3 περιοχών με υψηλότερο και χαμηλότερο εισόδημα\n",
    "top_income_areas = aggregated_income_data.orderBy(col(\"income_per_capita\").desc()).limit(3)\n",
    "low_income_areas = aggregated_income_data.orderBy(col(\"income_per_capita\").asc()).limit(3)\n",
    "\n",
    "\n",
    "\n",
    "# Φιλτράρισμα εγκλημάτων για τις περιοχές αυτές\n",
    "crime_top_income = crime_with_income.join(top_income_areas, \"COMM\", \"inner\")\n",
    "crime_low_income = crime_with_income.join(low_income_areas, \"COMM\", \"inner\")\n",
    "\n",
    "# Φόρτωση του RE (Race and Ethnicity codes)\n",
    "re_codes = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/RE_codes.csv\", header=False, inferSchema=True)\n",
    "re_codes = re_codes.withColumnRenamed(\"_c1\", \"Victim Descent\")\n",
    "\n",
    "# Αντιστοίχιση φυλετικής καταγωγής\n",
    "crime_top_income = crime_top_income.join(re_codes, crime_top_income[\"Vict Descent\"] == re_codes[\"_c0\"], \"inner\")\n",
    "crime_low_income = crime_low_income.join(re_codes, crime_low_income[\"Vict Descent\"] == re_codes[\"_c0\"], \"inner\")\n",
    "\n",
    "# Ομαδοποίηση ανά Victim Descent, μέτρηση, αύξουσα ταξινόμηση\n",
    "crime_top_income = crime_top_income.groupBy(\"Victim Descent\").agg(count(\"*\").alias(\"Victim Number\")).orderBy(col(\"Victim Number\").desc())\n",
    "print(\"Table for 3 regions with the highest per capita income\")\n",
    "crime_top_income.show(truncate=False)\n",
    "\n",
    "print(\"Table for 3 regions with the lowest per capita income\")\n",
    "crime_low_income = crime_low_income.groupBy(\"Victim Descent\").agg(count(\"*\").alias(\"Victim Number\")).orderBy(col(\"Victim Number\").desc())\n",
    "crime_low_income.show(truncate=False)\n",
    "\n",
    "end_rep = time.time()\n",
    "print(f\"Execution time with 4cores/8GB memory: {end_rep - start_rep:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bda0e1-7665-4f17-8657-54c09f7b722c",
   "metadata": {
    "tags": []
   },
   "source": [
    " # Query 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05af761-bb5b-4eed-921e-d93848c13054",
   "metadata": {},
   "source": [
    "#### 2executors × 4 cores/8GB memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea89cfbe-039c-4cdb-947a-18ac7c72df93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>64</td><td>application_1738075734771_0065</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-12.eu-central-1.compute.internal:20888/proxy/application_1738075734771_0065/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-100.eu-central-1.compute.internal:8042/node/containerlogs/container_1738075734771_0065_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------------+--------------+\n",
      "|division                         |average_distance  |incident_count|\n",
      "+---------------------------------+------------------+--------------+\n",
      "|7600 S. BROADWAY                 |2.696608257256237 |206784        |\n",
      "|1546 MARTIN LUTHER KING JR. BLVD.|2.6995220098942236|192226        |\n",
      "|12312 CULVER BLVD.               |3.876150507307626 |170903        |\n",
      "|251 E. 6TH ST.                   |1.1216874261027905|166698        |\n",
      "|11640 BURBANK BLVD.              |2.614233104134838 |164532        |\n",
      "|145 W. 108TH ST.                 |2.126199835576711 |161051        |\n",
      "|1358 N. WILCOX AVE.              |1.5539157186661017|150663        |\n",
      "|3400 S. CENTRAL AVE.             |2.059420966487143 |148757        |\n",
      "|1130 S. VERMONT AVE.             |1.8494716521262073|144962        |\n",
      "|11121 N. SEPULVEDA BLVD.         |4.712272528026431 |143600        |\n",
      "|3353 SAN FERNANDO RD.            |3.843277713528362 |142732        |\n",
      "| 6240 SYLMAR AVE.                |2.3962517064389357|142194        |\n",
      "|21501 SCHOENBORN ST.             |3.807711511366116 |138642        |\n",
      "|10250 ETIWANDA AVE.              |3.862776821785718 |137881        |\n",
      "|4861 VENICE BLVD.                |2.5989474794105263|136199        |\n",
      "|1401 W. 6TH ST.                  |1.6321100064449519|135948        |\n",
      "|1663 BUTLER AVE.                 |3.5757364263746556|134259        |\n",
      "|2175 JOHN S. GIBSON BLVD.        |4.079538821190032 |132911        |\n",
      "|19020 VANOWEN ST.                |3.579675402807391 |131502        |\n",
      "|2111 E. 1ST ST.                  |2.7243142497448996|114517        |\n",
      "+---------------------------------+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time with 2executors x 4 cores/8GB memory: 23.020 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, mean, lit, udf, desc, trim\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "import time\n",
    "# Ρύθμιση Spark Session για 1 core και 2 GB memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"1core/2 GB memory\") \\\n",
    "    .config(\"spark.executor.instances\", 2) \\\n",
    "    .config(\"spark.executor.cores\", 4) \\\n",
    "    .config(\"spark.executor.memory\", \"8G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "lapd_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_Police_Stations.csv\")\n",
    "\n",
    "# Φιλτράρουμε για να αποκλείσουμε τη γραμμή που περιέχει τη λέξη \"LOCATION\" στη στήλη `_c4`\n",
    "# Δηλαδή αφαιρούμε την 1η εγγραφη ώστε να έχουμε εγγραφες μόνο τα values.\n",
    "lapd_data = lapd_data.filter(~col(\"_c4\").contains(\"LOCATION\"))\n",
    "\n",
    "# Υπολογισμός απόστασης με Haversine Formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Ακτίνα της Γης σε χιλιόμετρα\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# UDF για τον υπολογισμό απόστασης\n",
    "haversine_udf = udf(haversine, DoubleType())\n",
    "\n",
    "# Καθαρισμός των ονομάτων στηλών στο crime_data\n",
    "crime_data = crime_data.select(\n",
    "    [trim(col(c)).alias(c.strip()) for c in crime_data.columns]\n",
    ")\n",
    "\n",
    "# Φιλτράρισμα για έλεγχο NULL τιμών στις στήλες LAT και LON και (0,0)\n",
    "crime_data = crime_data.filter(\n",
    "    (col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & ((col(\"LAT\") !=0) & (col(\"LON\") != 0))\n",
    ")\n",
    "\n",
    "lapd_data = lapd_data.filter(\n",
    "    (col(\"_c0\").isNotNull()) & (col(\"_c1\").isNotNull()) & ((col(\"_c0\") !=0) & (col(\"_c1\") != 0))\n",
    ")\n",
    "\n",
    "lapd_data = lapd_data.withColumn(\"_c0\", col(\"_c0\").cast(\"double\")).withColumn(\"_c1\", col(\"_c1\").cast(\"double\"))\n",
    "crime_data = crime_data.withColumn(\"LON\", col(\"LON\").cast(\"double\")).withColumn(\"LAT\", col(\"LAT\").cast(\"double\"))\n",
    "\n",
    "crime_data = crime_data.withColumn(\"AREA\", col(\"AREA\").cast(\"int\"))\n",
    "lapd_data = lapd_data.withColumn(\"_c5\", col(\"_c5\").cast(\"int\"))\n",
    "\n",
    "# Join μεταξύ crime_data και LAPD\n",
    "crime_with_lapd = crime_data.join(\n",
    "    lapd_data,\n",
    "    crime_data[\"AREA\"] == lapd_data[\"_c5\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός αποστάσεων\n",
    "crime_with_lapd = crime_with_lapd.withColumn(\n",
    "    \"distance\",\n",
    "    haversine_udf(\n",
    "        col(\"_c1\"), col(\"_c0\"),\n",
    "        col(\"LAT\"), col(\"LON\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ομαδοποίηση ανά τμήμα και υπολογισμός αποστάσεων και αριθμού περιστατικών\n",
    "closest_precinct = crime_with_lapd.groupBy(\"_c5\", \"_c4\").agg(\n",
    "    mean(\"distance\").alias(\"average_distance\"),  # Μέση απόσταση\n",
    "    count(\"*\").alias(\"incident_count\")  # Αριθμός περιστατικών\n",
    ")\n",
    "\n",
    "# Μετονομασία της στήλης _c4 σε division\n",
    "results = closest_precinct.select(\n",
    "    col(\"_c4\").alias(\"division\"),\n",
    "    col(\"average_distance\"),\n",
    "    col(\"incident_count\")\n",
    ")\n",
    "\n",
    "# Ταξινόμηση αποτελεσμάτων κατά αριθμό περιστατικών σε φθίνουσα σειρά\n",
    "results = results.orderBy(col(\"incident_count\").desc())\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "results.show(truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Execution time with 2executors x 4 cores/8GB memory: {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a41f62-2390-4862-b4c7-627eb50ad1ff",
   "metadata": {},
   "source": [
    "#### 4executors × 2 cores/4GB memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8bdb72-0074-46d0-b9d8-0703466f5dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>66</td><td>application_1738075734771_0067</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-12.eu-central-1.compute.internal:20888/proxy/application_1738075734771_0067/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-228.eu-central-1.compute.internal:8042/node/containerlogs/container_1738075734771_0067_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------------+--------------+\n",
      "|division                         |average_distance  |incident_count|\n",
      "+---------------------------------+------------------+--------------+\n",
      "|7600 S. BROADWAY                 |2.696608257256237 |206784        |\n",
      "|1546 MARTIN LUTHER KING JR. BLVD.|2.6995220098942236|192226        |\n",
      "|12312 CULVER BLVD.               |3.876150507307626 |170903        |\n",
      "|251 E. 6TH ST.                   |1.1216874261027905|166698        |\n",
      "|11640 BURBANK BLVD.              |2.614233104134838 |164532        |\n",
      "|145 W. 108TH ST.                 |2.126199835576711 |161051        |\n",
      "|1358 N. WILCOX AVE.              |1.5539157186661017|150663        |\n",
      "|3400 S. CENTRAL AVE.             |2.059420966487143 |148757        |\n",
      "|1130 S. VERMONT AVE.             |1.8494716521262073|144962        |\n",
      "|11121 N. SEPULVEDA BLVD.         |4.712272528026431 |143600        |\n",
      "|3353 SAN FERNANDO RD.            |3.843277713528362 |142732        |\n",
      "| 6240 SYLMAR AVE.                |2.3962517064389357|142194        |\n",
      "|21501 SCHOENBORN ST.             |3.807711511366116 |138642        |\n",
      "|10250 ETIWANDA AVE.              |3.862776821785718 |137881        |\n",
      "|4861 VENICE BLVD.                |2.5989474794105263|136199        |\n",
      "|1401 W. 6TH ST.                  |1.6321100064449519|135948        |\n",
      "|1663 BUTLER AVE.                 |3.5757364263746556|134259        |\n",
      "|2175 JOHN S. GIBSON BLVD.        |4.079538821190032 |132911        |\n",
      "|19020 VANOWEN ST.                |3.579675402807391 |131502        |\n",
      "|2111 E. 1ST ST.                  |2.7243142497448996|114517        |\n",
      "+---------------------------------+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time with 4 executors, 2 cores/4GB memory: 78.524 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, mean, lit, udf, desc, trim\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "import time\n",
    "\n",
    "# Ρύθμιση Spark Session για 1 core και 2 GB memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"4executors/2core/2 GB memory\") \\\n",
    "    .config(\"spark.executor.instances\", 4) \\\n",
    "    .config(\"spark.executor.cores\", 2) \\\n",
    "    .config(\"spark.executor.memory\", \"4G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "lapd_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_Police_Stations.csv\")\n",
    "\n",
    "# Φιλτράρουμε για να αποκλείσουμε τη γραμμή που περιέχει τη λέξη \"LOCATION\" στη στήλη `_c4`\n",
    "# Δηλαδή αφαιρούμε την 1η εγγραφη ώστε να έχουμε εγγραφες μόνο τα values.\n",
    "lapd_data = lapd_data.filter(~col(\"_c4\").contains(\"LOCATION\"))\n",
    "\n",
    "# Υπολογισμός απόστασης με Haversine Formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Ακτίνα της Γης σε χιλιόμετρα\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# UDF για τον υπολογισμό απόστασης\n",
    "haversine_udf = udf(haversine, DoubleType())\n",
    "\n",
    "# Καθαρισμός των ονομάτων στηλών στο crime_data\n",
    "crime_data = crime_data.select(\n",
    "    [trim(col(c)).alias(c.strip()) for c in crime_data.columns]\n",
    ")\n",
    "\n",
    "# Φιλτράρισμα για έλεγχο NULL τιμών στις στήλες LAT και LON\n",
    "crime_data = crime_data.filter(\n",
    "    (col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & ((col(\"LAT\") !=0) & (col(\"LON\") != 0))\n",
    ")\n",
    "\n",
    "lapd_data = lapd_data.filter(\n",
    "    (col(\"_c0\").isNotNull()) & (col(\"_c1\").isNotNull()) & ((col(\"_c0\") !=0) & (col(\"_c1\") != 0))\n",
    ")\n",
    "\n",
    "lapd_data = lapd_data.withColumn(\"_c0\", col(\"_c0\").cast(\"double\")).withColumn(\"_c1\", col(\"_c1\").cast(\"double\"))\n",
    "crime_data = crime_data.withColumn(\"LON\", col(\"LON\").cast(\"double\")).withColumn(\"LAT\", col(\"LAT\").cast(\"double\"))\n",
    "\n",
    "crime_data = crime_data.withColumn(\"AREA\", col(\"AREA\").cast(\"int\"))\n",
    "lapd_data = lapd_data.withColumn(\"_c5\", col(\"_c5\").cast(\"int\"))\n",
    "\n",
    "# Join μεταξύ crime_data και LAPD\n",
    "crime_with_lapd = crime_data.join(\n",
    "    lapd_data,\n",
    "    crime_data[\"AREA\"] == lapd_data[\"_c5\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός αποστάσεων\n",
    "crime_with_lapd = crime_with_lapd.withColumn(\n",
    "    \"distance\",\n",
    "    haversine_udf(\n",
    "        col(\"_c1\"), col(\"_c0\"),\n",
    "        col(\"LAT\"), col(\"LON\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ομαδοποίηση ανά τμήμα και υπολογισμός αποστάσεων και αριθμού περιστατικών\n",
    "closest_precinct = crime_with_lapd.groupBy(\"_c5\", \"_c4\").agg(\n",
    "    mean(\"distance\").alias(\"average_distance\"),  # Μέση απόσταση\n",
    "    count(\"*\").alias(\"incident_count\")  # Αριθμός περιστατικών\n",
    ")\n",
    "\n",
    "# Μετονομασία της στήλης _c4 σε division\n",
    "results = closest_precinct.select(\n",
    "    col(\"_c4\").alias(\"division\"),\n",
    "    col(\"average_distance\"),\n",
    "    col(\"incident_count\")\n",
    ")\n",
    "\n",
    "# Ταξινόμηση αποτελεσμάτων κατά αριθμό περιστατικών σε φθίνουσα σειρά\n",
    "results = results.orderBy(col(\"incident_count\").desc())\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "results.show(truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Execution time with 4 executors, 2 cores/4GB memory: {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc90c84-7742-47aa-9a07-12fa0c8fb341",
   "metadata": {},
   "source": [
    "#### 8executors × 1 core/2 GB memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fe42f6-51ad-4311-898b-08dbd8e8cc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>68</td><td>application_1738075734771_0069</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-12.eu-central-1.compute.internal:20888/proxy/application_1738075734771_0069/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-241.eu-central-1.compute.internal:8042/node/containerlogs/container_1738075734771_0069_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------------+--------------+\n",
      "|division                         |average_distance  |incident_count|\n",
      "+---------------------------------+------------------+--------------+\n",
      "|7600 S. BROADWAY                 |2.696608257256237 |206784        |\n",
      "|1546 MARTIN LUTHER KING JR. BLVD.|2.6995220098942236|192226        |\n",
      "|12312 CULVER BLVD.               |3.876150507307626 |170903        |\n",
      "|251 E. 6TH ST.                   |1.1216874261027905|166698        |\n",
      "|11640 BURBANK BLVD.              |2.614233104134838 |164532        |\n",
      "|145 W. 108TH ST.                 |2.126199835576711 |161051        |\n",
      "|1358 N. WILCOX AVE.              |1.5539157186661017|150663        |\n",
      "|3400 S. CENTRAL AVE.             |2.059420966487143 |148757        |\n",
      "|1130 S. VERMONT AVE.             |1.8494716521262073|144962        |\n",
      "|11121 N. SEPULVEDA BLVD.         |4.712272528026431 |143600        |\n",
      "|3353 SAN FERNANDO RD.            |3.843277713528362 |142732        |\n",
      "| 6240 SYLMAR AVE.                |2.3962517064389357|142194        |\n",
      "|21501 SCHOENBORN ST.             |3.807711511366116 |138642        |\n",
      "|10250 ETIWANDA AVE.              |3.862776821785718 |137881        |\n",
      "|4861 VENICE BLVD.                |2.5989474794105263|136199        |\n",
      "|1401 W. 6TH ST.                  |1.6321100064449519|135948        |\n",
      "|1663 BUTLER AVE.                 |3.5757364263746556|134259        |\n",
      "|2175 JOHN S. GIBSON BLVD.        |4.079538821190032 |132911        |\n",
      "|19020 VANOWEN ST.                |3.579675402807391 |131502        |\n",
      "|2111 E. 1ST ST.                  |2.7243142497448996|114517        |\n",
      "+---------------------------------+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time with 8 executors, 1 core/2GB memory: 83.982 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, mean, lit, udf, desc, trim\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "import time\n",
    "\n",
    "# Ρύθμιση Spark Session για 1 core και 2 GB memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"8executors/1core/2 GB memory\") \\\n",
    "    .config(\"spark.executor.instances\", 8) \\\n",
    "    .config(\"spark.executor.cores\", 1) \\\n",
    "    .config(\"spark.executor.memory\", \"2G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start  = time.time()\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_data = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group27/Crime_Data/\")\n",
    "lapd_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_Police_Stations.csv\")\n",
    "\n",
    "# Φιλτράρουμε για να αποκλείσουμε τη γραμμή που περιέχει τη λέξη \"LOCATION\" στη στήλη `_c4`.\n",
    "# Δηλαδή αφαιρούμε την 1η εγγραφη ώστε να έχουμε εγγραφες μόνο τα values.\n",
    "lapd_data = lapd_data.filter(~col(\"_c4\").contains(\"LOCATION\"))\n",
    "\n",
    "# Υπολογισμός απόστασης με Haversine Formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Ακτίνα της Γης σε χιλιόμετρα\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# UDF για τον υπολογισμό απόστασης\n",
    "haversine_udf = udf(haversine, DoubleType())\n",
    "\n",
    "# Καθαρισμός των ονομάτων στηλών στο crime_data\n",
    "crime_data = crime_data.select(\n",
    "    [trim(col(c)).alias(c.strip()) for c in crime_data.columns]\n",
    ")\n",
    "\n",
    "# Φιλτράρισμα για έλεγχο NULL τιμών στις στήλες LAT και LON\n",
    "crime_data = crime_data.filter(\n",
    "    (col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & ((col(\"LAT\") !=0) & (col(\"LON\") != 0))\n",
    ")\n",
    "\n",
    "lapd_data = lapd_data.filter(\n",
    "    (col(\"_c0\").isNotNull()) & (col(\"_c1\").isNotNull()) & ((col(\"_c0\") !=0) & (col(\"_c1\") != 0))\n",
    ")\n",
    "\n",
    "lapd_data = lapd_data.withColumn(\"_c0\", col(\"_c0\").cast(\"double\")).withColumn(\"_c1\", col(\"_c1\").cast(\"double\"))\n",
    "crime_data = crime_data.withColumn(\"LON\", col(\"LON\").cast(\"double\")).withColumn(\"LAT\", col(\"LAT\").cast(\"double\"))\n",
    "\n",
    "crime_data = crime_data.withColumn(\"AREA\", col(\"AREA\").cast(\"int\"))\n",
    "lapd_data = lapd_data.withColumn(\"_c5\", col(\"_c5\").cast(\"int\"))\n",
    "\n",
    "# Join μεταξύ crime_data και LAPD\n",
    "crime_with_lapd = crime_data.join(\n",
    "    lapd_data,\n",
    "    crime_data[\"AREA\"] == lapd_data[\"_c5\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Υπολογισμός αποστάσεων\n",
    "crime_with_lapd = crime_with_lapd.withColumn(\n",
    "    \"distance\",\n",
    "    haversine_udf(\n",
    "        col(\"_c1\"), col(\"_c0\"),\n",
    "        col(\"LAT\"), col(\"LON\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ομαδοποίηση ανά τμήμα και υπολογισμός αποστάσεων και αριθμού περιστατικών\n",
    "closest_precinct = crime_with_lapd.groupBy(\"_c5\", \"_c4\").agg(\n",
    "    mean(\"distance\").alias(\"average_distance\"),  # Μέση απόσταση\n",
    "    count(\"*\").alias(\"incident_count\")  # Αριθμός περιστατικών\n",
    ")\n",
    "\n",
    "# Μετονομασία της στήλης _c4 σε division\n",
    "results = closest_precinct.select(\n",
    "    col(\"_c4\").alias(\"division\"),\n",
    "    col(\"average_distance\"),\n",
    "    col(\"incident_count\")\n",
    ")\n",
    "\n",
    "# Ταξινόμηση αποτελεσμάτων κατά αριθμό περιστατικών σε φθίνουσα σειρά\n",
    "results = results.orderBy(col(\"incident_count\").desc())\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων\n",
    "results.show(truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Execution time with 8 executors, 1 core/2GB memory: {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcecac-6f94-41b7-a1ad-47520c68082f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
